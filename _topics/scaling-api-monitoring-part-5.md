---
title: "Scaling Your API Part 5: Monitoring & Performance"
category: Architecture
tags:
  - monitoring
  - performance
  - api
  - observability
  - metrics
series: "Scaling Your API"
part: 5
summary: Learn how to monitor your API and improve performance ‚Äî with simple explanations and practical examples anyone can understand.
related:
  - scaling-api-1-to-1-million-rps
  - scaling-api-design-architecture-part-2
  - choosing-the-right-database
  - scaling-api-load-balancing-part-4
---

> **üìö This is Part 5 of the "Scaling Your API" Series**
> - **[Part 1: Performance & Infrastructure ‚Üê]({{ site.baseurl }}{% link _topics/scaling-api-1-to-1-million-rps.md %})** - Technical techniques to handle millions of requests
> - **[Part 2: Design & Architecture ‚Üê]({{ site.baseurl }}{% link _topics/scaling-api-design-architecture-part-2.md %})** - Organizational strategies and API design patterns
> - **[Part 3: Choosing the Right Database ‚Üê]({{ site.baseurl }}{% link _topics/choosing-the-right-database.md %})** - Database selection for your API
> - **[Part 4: Load Balancing & High Availability ‚Üê]({{ site.baseurl }}{% link _topics/scaling-api-load-balancing-part-4.md %})** - Keeping your API always available
> - **Part 5 (this page):** Monitoring & Performance - Tracking and improving API performance

## Why Monitor Your API?

> **Think of it like this:** Monitoring your API is like having a dashboard in your car. You need to know your speed, fuel level, and engine temperature ‚Äî before problems happen!

### Without Monitoring ‚ùå

```
User: "Your API is down!"
You: "What? Since when?"
User: "For the last 2 hours!"
You: *panic* üò±

Problem: You didn't know there was an issue until users complained
```

### With Monitoring ‚úÖ

```
11:00 AM - Monitor detects high error rate
11:01 AM - Alert sent to your phone üì±
11:02 AM - You start investigating
11:05 AM - Problem fixed

Problem: Caught and fixed in 5 minutes, most users didn't even notice!
```

---

## The 4 Golden Signals (What to Monitor)

> **These 4 metrics tell you everything about your API's health:**

<div class="mermaid">
flowchart TD
    MONITOR["üìä Monitor Your API"]
    
    LATENCY["‚è±Ô∏è Latency<br/>(How fast?)"]
    TRAFFIC["üìà Traffic<br/>(How busy?)"]
    ERRORS["‚ùå Errors<br/>(What's broken?)"]
    SATURATION["üî• Saturation<br/>(How full?)"]
    
    MONITOR --> LATENCY
    MONITOR --> TRAFFIC
    MONITOR --> ERRORS
    MONITOR --> SATURATION
    
    style MONITOR fill:#dbeafe,stroke:#2563eb
    style LATENCY fill:#d1fae5,stroke:#059669
    style TRAFFIC fill:#fef3c7,stroke:#d97706
    style ERRORS fill:#fee,stroke:#f00
    style SATURATION fill:#fce7f3,stroke:#db2777
</div>

---

### 1. Latency (How Fast Is Your API?)

> **Latency = How long it takes to respond to a request**

**Good API:**
```
User makes request at 10:00:00.000
API responds at     10:00:00.050  (50ms later)

Latency: 50ms ‚úÖ (Very fast!)
```

**Slow API:**
```
User makes request at 10:00:00.000
API responds at     10:00:02.500  (2.5 seconds later)

Latency: 2,500ms ‚ùå (Too slow!)
```

**What to Aim For:**
```
Excellent:   < 100ms
Good:        100-300ms
Acceptable:  300-1000ms
Slow:        > 1000ms (need to optimize!)
```

**Real-World Example:**
```javascript
// Measure latency in your API
app.get('/api/users/:id', async (req, res) => {
  const startTime = Date.now();
  
  const user = await database.getUser(req.params.id);
  
  const latency = Date.now() - startTime;
  console.log(`Request took ${latency}ms`);
  
  res.json(user);
});

// Output:
// Request took 45ms ‚úÖ
// Request took 52ms ‚úÖ
// Request took 1200ms ‚ùå (Something is wrong!)
```

---

### 2. Traffic (How Busy Is Your API?)

> **Traffic = Number of requests your API receives**

**Why it matters:**
```
Normal day:     1,000 requests/second
Black Friday:   10,000 requests/second

If you don't monitor traffic, you won't know when to add more servers!
```

**Example Traffic Patterns:**

<div class="mermaid">
graph LR
    A[Morning: 1000 req/s] --> B[Noon: 5000 req/s]
    B --> C[Evening: 3000 req/s]
    C --> D[Night: 500 req/s]
    
    style A fill:#d1fae5
    style B fill:#fef3c7
    style C fill:#fef3c7
    style D fill:#d1fae5
</div>

**What to Track:**
```
- Requests per second (RPS)
- Requests per minute (RPM)
- Most popular endpoints
- Peak traffic times
```

---

### 3. Errors (What's Breaking?)

> **Errors = Requests that fail**

**Types of Errors:**

```
200 OK           ‚úÖ Success! Everything worked
400 Bad Request  ‚ö†Ô∏è  User sent invalid data
401 Unauthorized ‚ö†Ô∏è  User not logged in
404 Not Found    ‚ö†Ô∏è  Endpoint doesn't exist
500 Server Error ‚ùå YOUR API IS BROKEN!
503 Unavailable  ‚ùå Server overloaded!
```

**Error Rate Example:**
```
Total Requests: 1,000
Errors: 10
Error Rate: 1% (acceptable)

Total Requests: 1,000
Errors: 500
Error Rate: 50% (CRITICAL PROBLEM! üö®)
```

**What Good Looks Like:**
```
Target Error Rate: < 0.1% (1 error per 1,000 requests)
Acceptable: < 1%
Problem: > 5%
Critical: > 10%
```

---

### 4. Saturation (How Full Is Your System?)

> **Saturation = How close to maximum capacity**

**Think of it like a highway:**
```
10 cars on highway   = 10% saturation  ‚úÖ (Fast and smooth)
50 cars on highway   = 50% saturation  ‚úÖ (Still good)
80 cars on highway   = 80% saturation  ‚ö†Ô∏è  (Slowing down)
100 cars on highway  = 100% saturation ‚ùå (Traffic jam!)
```

**What to Monitor:**

```
CPU Usage:
- 30% = Healthy ‚úÖ
- 70% = Getting busy ‚ö†Ô∏è
- 90% = Near limit! ‚ùå
- 100% = SLOW! Need more servers!

Memory Usage:
- 40% = Good ‚úÖ
- 80% = Watch carefully ‚ö†Ô∏è
- 95% = Critical! ‚ùå

Database Connections:
- 20/100 = Plenty available ‚úÖ
- 90/100 = Running out! ‚ö†Ô∏è
- 100/100 = Requests failing! ‚ùå
```

---

## Simple Monitoring Setup (Step-by-Step)

### Option 1: Basic Logging (Free, 10 Minutes)

**Step 1: Add logging to your API**

```javascript
// Log every request
app.use((req, res, next) => {
  const startTime = Date.now();
  
  // When response finishes
  res.on('finish', () => {
    const duration = Date.now() - startTime;
    
    console.log({
      method: req.method,
      path: req.path,
      status: res.statusCode,
      duration: `${duration}ms`,
      timestamp: new Date().toISOString()
    });
  });
  
  next();
});
```

**Step 2: Check your logs**

```bash
# View recent logs
tail -f /var/log/myapi.log

# Output:
{ method: 'GET', path: '/api/users/123', status: 200, duration: '45ms', timestamp: '2024-01-01T10:00:00Z' }
{ method: 'POST', path: '/api/orders', status: 201, duration: '120ms', timestamp: '2024-01-01T10:00:01Z' }
{ method: 'GET', path: '/api/users/456', status: 500, duration: '5000ms', timestamp: '2024-01-01T10:00:02Z' }
                                            ‚Üë ERROR! Took 5 seconds!
```

**You now know:**
- ‚úÖ Which requests are slow
- ‚úÖ Which requests are failing
- ‚úÖ When problems happen

---

### Option 2: Simple Dashboard (Free, 30 Minutes)

**Tools:** Express + Simple Stats Endpoint

```javascript
// Track stats in memory
let stats = {
  totalRequests: 0,
  successfulRequests: 0,
  failedRequests: 0,
  totalDuration: 0
};

// Update stats for each request
app.use((req, res, next) => {
  const startTime = Date.now();
  
  stats.totalRequests++;
  
  res.on('finish', () => {
    const duration = Date.now() - startTime;
    stats.totalDuration += duration;
    
    if (res.statusCode < 400) {
      stats.successfulRequests++;
    } else {
      stats.failedRequests++;
    }
  });
  
  next();
});

// Dashboard endpoint
app.get('/admin/stats', (req, res) => {
  const avgDuration = stats.totalDuration / stats.totalRequests;
  const errorRate = (stats.failedRequests / stats.totalRequests) * 100;
  
  res.json({
    totalRequests: stats.totalRequests,
    successRate: `${(stats.successfulRequests / stats.totalRequests * 100).toFixed(2)}%`,
    errorRate: `${errorRate.toFixed(2)}%`,
    avgResponseTime: `${avgDuration.toFixed(0)}ms`
  });
});
```

**Visit http://yourapi.com/admin/stats:**
```json
{
  "totalRequests": 15234,
  "successRate": "99.2%",
  "errorRate": "0.8%",
  "avgResponseTime": "67ms"
}
```

**Now you can check your API health anytime! ‚úÖ**

---

### Option 3: Professional Monitoring (Paid, 1 Hour Setup)

#### Best Tools for Beginners:

| Tool | Cost | Best For | Setup Time |
|------|------|----------|------------|
| **Datadog** | $15/month | Beautiful dashboards | 30 min ‚≠ê |
| **New Relic** | Free tier available | Easy to use | 30 min ‚≠ê |
| **Grafana Cloud** | Free tier | Open source | 1 hour ‚≠ê‚≠ê |
| **AWS CloudWatch** | ~$10/month | AWS users | 20 min ‚≠ê |

---

#### Example: Setting Up Datadog (Simple!)

**Step 1: Sign up at datadog.com**

**Step 2: Install agent on your server**
```bash
# One command!
DD_API_KEY=your-key bash -c "$(curl -L https://s3.amazonaws.com/dd-agent/scripts/install_script.sh)"
```

**Step 3: Install library in your app**
```bash
npm install dd-trace
```

**Step 4: Add to your code**
```javascript
// At the very top of your main file
require('dd-trace').init();

// That's it! üéâ
```

**Step 5: Check Datadog dashboard**

You now see:
- üìä Request rate graph
- ‚è±Ô∏è Average response time
- ‚ùå Error rate
- üñ•Ô∏è CPU & memory usage
- üìà Everything automatically!

---

## Setting Up Alerts (Get Notified When Things Break)

> **Alerts = Automatic notifications when something is wrong**

### Alert Example: High Error Rate

**What you want:**
```
If error rate > 5% for more than 5 minutes
‚Üí Send me a text message! üì±
```

**How to set up (Example with Datadog):**

```
1. Go to Monitors ‚Üí New Monitor
2. Choose "Metric Monitor"
3. Set condition:
   - Metric: error_rate
   - Alert when: above 5%
   - For: 5 minutes
4. Set notification:
   - Send to: your-phone@sms.com
   - Message: "API errors are high! Check immediately"
5. Save!
```

**Now you get alerted the moment things break ‚úÖ**

---

### Smart Alerts (What to Alert On)

#### ‚úÖ DO Alert On These (Important!):

```
1. Error Rate > 5%
   ‚Üí Something is broken!

2. Response Time > 1 second
   ‚Üí API is too slow!

3. Traffic drops to 0
   ‚Üí API might be down!

4. CPU > 90% for 10 minutes
   ‚Üí Need more servers!

5. Database connections > 95%
   ‚Üí About to run out!
```

#### ‚ùå DON'T Alert On These (Too Noisy):

```
1. Single error (happens all the time)
2. Response time spike for 1 second (temporary)
3. CPU > 50% (still plenty of capacity)
4. One slow request (users make mistakes)
```

**Golden Rule:** Only alert on things that need immediate action!

---

## Performance Optimization (Making Your API Faster)

### Step 1: Find the Slow Parts

**Add timing to your code:**

```javascript
app.get('/api/orders/:id', async (req, res) => {
  console.time('Total Request');
  
  console.time('Database Query');
  const order = await db.query('SELECT * FROM orders WHERE id = $1', [req.params.id]);
  console.timeEnd('Database Query');  // Output: Database Query: 150ms
  
  console.time('User Lookup');
  const user = await db.query('SELECT * FROM users WHERE id = $1', [order.userId]);
  console.timeEnd('User Lookup');  // Output: User Lookup: 120ms
  
  console.time('Product Details');
  const products = await getProductDetails(order.items);
  console.timeEnd('Product Details');  // Output: Product Details: 800ms ‚Üê SLOW!
  
  console.timeEnd('Total Request');  // Output: Total Request: 1070ms
  
  res.json({ order, user, products });
});
```

**Now you know:** Getting product details is the slow part!

---

### Step 2: Add Caching (Make It 10x Faster)

**Before (Slow):**
```javascript
// Every request hits database (slow!)
app.get('/api/products/:id', async (req, res) => {
  const product = await db.query('SELECT * FROM products WHERE id = $1', [req.params.id]);
  res.json(product);
  // Response time: 150ms
});
```

**After (Fast):**
```javascript
const redis = require('redis');
const client = redis.createClient();

app.get('/api/products/:id', async (req, res) => {
  const cacheKey = `product:${req.params.id}`;
  
  // Try cache first
  const cached = await client.get(cacheKey);
  if (cached) {
    return res.json(JSON.parse(cached));  // Response time: 2ms ‚ö°
  }
  
  // Cache miss: get from database
  const product = await db.query('SELECT * FROM products WHERE id = $1', [req.params.id]);
  
  // Store in cache for 5 minutes
  await client.setex(cacheKey, 300, JSON.stringify(product));
  
  res.json(product);  // Response time: 150ms first time, then 2ms
});
```

**Result: 75x faster! (150ms ‚Üí 2ms)**

---

### Step 3: Database Indexes (Speed Up Queries)

**Problem: Slow Query**
```sql
-- Without index: Scans ALL 1 million users (SLOW!)
SELECT * FROM users WHERE email = 'john@example.com';
-- Query time: 2000ms ‚ùå
```

**Solution: Add Index**
```sql
-- Create index on email column
CREATE INDEX idx_users_email ON users(email);

-- Same query now:
SELECT * FROM users WHERE email = 'john@example.com';
-- Query time: 5ms ‚úÖ (400x faster!)
```

**When to Add Indexes:**
```
Add index if you query by that column frequently:
- User IDs ‚úÖ (query all the time)
- Email addresses ‚úÖ (login queries)
- Product SKUs ‚úÖ (product lookups)
- Order dates ‚úÖ (date range queries)
```

---

### Step 4: Reduce Data Transfer

**Bad: Sending Too Much Data**
```javascript
// Returns EVERYTHING (including huge description)
app.get('/api/products', async (req, res) => {
  const products = await db.query('SELECT * FROM products');
  res.json(products);  
  // Response: 5 MB of data
  // Time: 500ms ‚ùå
});
```

**Good: Send Only What's Needed**
```javascript
// Returns only ID, name, price (what user sees in list)
app.get('/api/products', async (req, res) => {
  const products = await db.query('SELECT id, name, price FROM products');
  res.json(products);  
  // Response: 100 KB of data
  // Time: 50ms ‚úÖ (10x faster!)
});

// Full details only when user clicks product
app.get('/api/products/:id', async (req, res) => {
  const product = await db.query('SELECT * FROM products WHERE id = $1', [req.params.id]);
  res.json(product);
});
```

---

### Step 5: Parallel Requests (Do Multiple Things at Once)

**Bad: Sequential (Slow)**
```javascript
// Do one thing at a time (SLOW!)
app.get('/api/dashboard', async (req, res) => {
  const user = await getUser();         // 100ms
  const orders = await getOrders();     // 150ms
  const products = await getProducts(); // 200ms
  
  res.json({ user, orders, products });
  // Total time: 450ms ‚ùå
});
```

**Good: Parallel (Fast)**
```javascript
// Do everything at the same time!
app.get('/api/dashboard', async (req, res) => {
  const [user, orders, products] = await Promise.all([
    getUser(),         // ‚Üê All 3 run simultaneously
    getOrders(),       // ‚Üê
    getProducts()      // ‚Üê
  ]);
  
  res.json({ user, orders, products });
  // Total time: 200ms ‚úÖ (2x faster!)
});
```

---

## Performance Monitoring Dashboard (What to Display)

### Simple Dashboard Example:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  API Performance Dashboard              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ  üöÄ Requests/Second: 1,234             ‚îÇ
‚îÇ  ‚è±Ô∏è  Avg Response Time: 67ms           ‚îÇ
‚îÇ  ‚úÖ Success Rate: 99.8%                 ‚îÇ
‚îÇ  ‚ùå Error Rate: 0.2%                    ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  üìä Slowest Endpoints:                  ‚îÇ
‚îÇ    1. POST /api/upload     - 2.3s      ‚îÇ
‚îÇ    2. GET /api/reports     - 890ms     ‚îÇ
‚îÇ    3. GET /api/analytics   - 450ms     ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  üî• Resource Usage:                     ‚îÇ
‚îÇ    CPU: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 45%                 ‚îÇ
‚îÇ    Memory: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 60%              ‚îÇ
‚îÇ    Database: ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 30%            ‚îÇ
‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Real-World Monitoring Examples

### Example 1: E-Commerce API

**What to Monitor:**
```
1. Checkout endpoint response time
   ‚Üí Alert if > 500ms (users abandon slow checkouts!)

2. Product search response time
   ‚Üí Alert if > 200ms (users expect instant search)

3. Payment gateway errors
   ‚Üí Alert immediately on ANY error (lost revenue!)

4. Shopping cart endpoint traffic
   ‚Üí Spike means potential sales increase

5. Database connection pool
   ‚Üí Alert if > 80% (about to run out)
```

**Dashboard:**
```
Top Priority Metrics:
- Checkout success rate: 98.5% ‚úÖ
- Average cart value: $67.32
- Payment failures: 1.2% ‚ö†Ô∏è (investigate!)
- Page load time: 1.2s
```

---

### Example 2: Social Media API

**What to Monitor:**
```
1. Feed load time
   ‚Üí Alert if > 300ms (users scroll fast!)

2. Image upload success rate
   ‚Üí Alert if < 95% (broken uploads frustrate users)

3. Real-time notification latency
   ‚Üí Should be < 1 second

4. API calls per user
   ‚Üí Detect unusual patterns (possible abuse)

5. Peak traffic times
   ‚Üí Know when to scale up
```

**Dashboard:**
```
Real-Time Metrics:
- Active users: 45,234
- Posts per second: 127
- Image uploads/min: 890
- Failed uploads: 12 (1.3%) ‚úÖ
- Average feed load: 245ms ‚úÖ
```

---

### Example 3: Banking API

**What to Monitor:**
```
1. Transaction endpoint errors
   ‚Üí Alert on ANY error (money is involved!)

2. Authentication failures
   ‚Üí Spike might indicate attack

3. Account balance query time
   ‚Üí Must be < 100ms (users check often)

4. Database replication lag
   ‚Üí Alert if > 1 second (stale data)

5. Security events
   ‚Üí Failed logins, suspicious patterns
```

**Dashboard:**
```
Critical Metrics:
- Transactions processed: 15,234
- Transaction errors: 0 ‚úÖ (must be zero!)
- Avg transaction time: 45ms ‚úÖ
- Failed auth attempts: 23 ‚ö†Ô∏è (monitor for attacks)
- Uptime today: 100% ‚úÖ
```

---

## Common Performance Problems & Solutions

### Problem 1: Slow Database Queries

**Symptom:**
```
API response time: 2000ms (way too slow!)
```

**Diagnosis:**
```javascript
// Add query timing
const start = Date.now();
const users = await db.query('SELECT * FROM users WHERE status = "active"');
console.log(`Query took ${Date.now() - start}ms`);
// Output: Query took 1800ms ‚Üê PROBLEM FOUND!
```

**Solution:**
```sql
-- Add index
CREATE INDEX idx_users_status ON users(status);

-- Now query takes 50ms instead of 1800ms ‚úÖ
```

---

### Problem 2: Memory Leak

**Symptom:**
```
Memory usage slowly increases over time
Hour 1: 200 MB
Hour 2: 400 MB
Hour 3: 600 MB
Hour 4: 800 MB
Hour 5: SERVER CRASH! ‚ùå
```

**Diagnosis:**
```javascript
// Bad: Storing data in global variable (never gets cleaned up!)
const cache = {};  // ‚Üê Memory leak!

app.get('/api/users/:id', async (req, res) => {
  cache[req.params.id] = await getUser(req.params.id);
  res.json(cache[req.params.id]);
});
// Cache grows forever, using more and more memory
```

**Solution:**
```javascript
// Good: Use Redis with expiration
app.get('/api/users/:id', async (req, res) => {
  const cached = await redis.get(`user:${req.params.id}`);
  if (cached) return res.json(JSON.parse(cached));
  
  const user = await getUser(req.params.id);
  await redis.setex(`user:${req.params.id}`, 300, JSON.stringify(user));  // Auto-expires in 5 min
  res.json(user);
});
// Memory stays constant ‚úÖ
```

---

### Problem 3: Too Many Database Connections

**Symptom:**
```
Error: "Too many connections to database"
Some requests fail randomly
```

**Diagnosis:**
```javascript
// Bad: Creating new connection for each request
app.get('/api/users/:id', async (req, res) => {
  const db = new Database();  // ‚Üê New connection every time!
  const user = await db.query(...);
  res.json(user);
  // Connection not closed!
});
```

**Solution:**
```javascript
// Good: Use connection pool (reuse connections)
const pool = new Pool({
  max: 20,  // Maximum 20 connections
  min: 5    // Always keep 5 ready
});

app.get('/api/users/:id', async (req, res) => {
  const user = await pool.query(...);  // ‚Üê Reuses existing connection
  res.json(user);
});
// Connections are reused efficiently ‚úÖ
```

---

## Monitoring Checklist

Before going to production:

- [ ] **Basic Logging:** Every request logged with duration
- [ ] **Error Tracking:** All errors captured with details
- [ ] **Performance Metrics:** Latency, traffic, errors, saturation tracked
- [ ] **Alerts Set Up:** Get notified when problems occur
- [ ] **Dashboard:** Can see API health at a glance
- [ ] **Database Monitoring:** Query performance tracked
- [ ] **Resource Monitoring:** CPU, memory, disk usage tracked
- [ ] **Uptime Monitoring:** External service checks if API is reachable
- [ ] **Regular Reviews:** Check metrics weekly
- [ ] **Documentation:** Team knows how to read dashboards

---

## Simple Monitoring Tools Comparison

| Tool | Cost | Complexity | Best For | Setup Time |
|------|------|------------|----------|------------|
| **Console.log** | Free | Very Low ‚≠ê | Learning/testing | 5 min |
| **Morgan (Express)** | Free | Low ‚≠ê | Simple logging | 10 min |
| **PM2 Monitoring** | Free | Low ‚≠ê | Node.js apps | 15 min |
| **Datadog** | $15/mo | Medium ‚≠ê‚≠ê | Professional teams | 30 min |
| **New Relic** | Free tier | Medium ‚≠ê‚≠ê | Great dashboards | 30 min |
| **Grafana + Prometheus** | Free | High ‚≠ê‚≠ê‚≠ê | Self-hosted | 2 hours |
| **AWS CloudWatch** | ~$10/mo | Low ‚≠ê | AWS users | 20 min |

---

## Quick Start: 15-Minute Monitoring Setup

**Step 1: Install Morgan (Request Logger)**
```bash
npm install morgan
```

**Step 2: Add to Your App**
```javascript
const morgan = require('morgan');

// Log every request
app.use(morgan('combined'));

// Now you see:
// 127.0.0.1 - - [01/Jan/2024:10:00:00 +0000] "GET /api/users/123 HTTP/1.1" 200 1234 "-" "Mozilla/5.0"
```

**Step 3: Add Error Tracking**
```javascript
app.use((err, req, res, next) => {
  console.error({
    error: err.message,
    stack: err.stack,
    path: req.path,
    method: req.method,
    timestamp: new Date()
  });
  
  res.status(500).json({ error: 'Internal server error' });
});
```

**Step 4: Create Health Endpoint**
```javascript
app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    uptime: process.uptime(),
    memory: process.memoryUsage(),
    timestamp: new Date()
  });
});
```

**Step 5: Set Up Uptime Monitoring (Free)**

Go to **uptimerobot.com**:
1. Sign up (free)
2. Add your API: `https://yourapi.com/health`
3. Check every 5 minutes
4. Email you if it's down

**Done! You now have basic monitoring in 15 minutes! ‚úÖ**

---

## Summary: Monitoring & Performance

> **The Golden Rules:**
> 
> 1. **Monitor the 4 Golden Signals** ‚Üí Latency, Traffic, Errors, Saturation
> 2. **Set up alerts** ‚Üí Know about problems before users complain
> 3. **Start simple** ‚Üí Basic logging is better than nothing
> 4. **Measure before optimizing** ‚Üí Find the slow parts first
> 5. **Cache aggressively** ‚Üí Can make APIs 10-100x faster

### What Good Monitoring Gives You

```
Without Monitoring:
- Find out about problems from angry users ‚ùå
- Don't know what's slow ‚ùå
- Can't prove improvements ‚ùå
- Constantly putting out fires ‚ùå

With Monitoring:
- Know about problems before users ‚úÖ
- See exactly what's slow ‚úÖ
- Measure impact of optimizations ‚úÖ
- Proactively prevent issues ‚úÖ
- Sleep better at night üò¥‚úÖ
```

### Progressive Monitoring Approach

```
Week 1: Basic Logging
- Console.log with timestamps
- Error tracking
- Cost: $0

Week 2: Simple Dashboard
- Request counter
- Average response time
- Error rate
- Cost: $0

Week 3: Add Alerts
- High error rate alert
- Slow response time alert
- Cost: $0 (use free tier)

Week 4: Professional Tool
- Datadog or New Relic
- Beautiful dashboards
- Advanced alerts
- Cost: ~$15/month

Month 2+: Fine-tune
- Optimize based on data
- Add custom metrics
- Improve alerts
```

---

## Continue the Series

This is **Part 5** of the "Scaling Your API" series:

- **[Part 1: Performance & Infrastructure ‚Üí]({{ site.baseurl }}{% link _topics/scaling-api-1-to-1-million-rps.md %})** - Technical techniques to handle millions of requests
- **[Part 2: Design & Architecture ‚Üí]({{ site.baseurl }}{% link _topics/scaling-api-design-architecture-part-2.md %})** - Organizational strategies and API design patterns
- **[Part 3: Choosing the Right Database ‚Üí]({{ site.baseurl }}{% link _topics/choosing-the-right-database.md %})** - Database selection for your API
- **[Part 4: Load Balancing & High Availability ‚Üí]({{ site.baseurl }}{% link _topics/scaling-api-load-balancing-part-4.md %})** - Keeping your API always available
- **Part 5:** Monitoring & Performance ‚Üê You are here

---

## Further Reading

- **[Datadog Documentation](https://docs.datadoghq.com/)** ‚Äî Learn professional monitoring
- **[Prometheus & Grafana Guide](https://prometheus.io/docs/introduction/overview/)** ‚Äî Open source monitoring
- **[Google SRE Book](https://sre.google/books/)** ‚Äî How Google monitors services
- **[New Relic University](https://learn.newrelic.com/)** ‚Äî Free monitoring courses

---

**Remember:** You can't improve what you don't measure. Start monitoring today, even if it's just basic logging. Your future self (and your users) will thank you!


