---
title: "Case Study: How Airbnb Solved Metric Chaos (Part 1 - The Problem)"
category: Case Studies
tags:
  - case-study
  - airbnb
  - data-quality
  - metrics
  - analytics
  - real-world
series: "Airbnb Metric Consistency"
part: 1
summary: How Airbnb discovered their biggest data problem wasn't big data â€” it was getting everyone to agree on what "bookings" actually means.
related:
  - airbnb-metric-consistency-part-2-solution
---

> **Part 1 of the Airbnb Metric Consistency Series**
> 
> **Important Note:** This article is based on my understanding after reading the [Airbnb Engineering blog](https://medium.com/airbnb-engineering) and various articles about their Minerva platform. I'm trying to demystify and explain these concepts in an accessible way. If you want to understand exactly what Airbnb built, please refer to the original articles linked in the Further Reading section.
> 
> **The surprising problem:** Airbnb had world-class data infrastructure handling billions of events. But they couldn't agree on basic numbers like "How many bookings did we have yesterday?"
> 
> **This article** explains why metric inconsistency is one of the hardest problems in data â€” and why it matters more than you think.
> 
> **Next:** [Part 2 - The Solution (Minerva Platform) â†’]({{ site.baseurl }}{% link _topics/airbnb-metric-consistency-part-2-solution.md %})

## Introduction: A Simple Question, A Hundred Answers

Imagine this scenario at an Airbnb meeting in 2018:

```
CEO: "How many bookings did we have last month?"

Product Manager: "500,000 bookings"
Marketing Team:   "520,000 bookings"
Finance Team:     "480,000 bookings"
Data Science:     "515,000 bookings"
Engineering:      "505,000 bookings"

CEO: "...which number is correct?"

Everyone: "Mine is!"
```

**This actually happened.** And not just once â€” it happened daily across thousands of metrics.

> **Think of it like this:** Imagine 5 people measuring the same room with different rulers, and each ruler shows a different length. That's what was happening with Airbnb's data.

This is the story of how Airbnb fixed one of the most common (and most expensive) problems in data: **metric inconsistency**.

---

## What is Metric Inconsistency?

### The Simple Explanation

> **Metric inconsistency** is when the same number means different things to different people â€” or when different teams calculate the same metric in different ways.

**Real example from Airbnb:**

```
Question: "What is a 'booking'?"

Product team's definition:
âœ… User clicks "Book" button
âœ… Includes canceled bookings
Result: 520,000 bookings

Finance team's definition:
âœ… Payment successfully processed
âŒ Excludes canceled bookings
Result: 480,000 bookings

Marketing team's definition:
âœ… User completes booking flow
âœ… Includes pending payments
Result: 500,000 bookings

All three are measuring "bookings"
But getting different numbers!
```

### Why This Happens

<div class="mermaid">
flowchart TD
    START["One Concept:<br/>'Bookings'"]
    
    START --> TEAM1["Product Team<br/>Builds Dashboard 1<br/>Definition A"]
    START --> TEAM2["Marketing Team<br/>Builds Dashboard 2<br/>Definition B"]
    START --> TEAM3["Finance Team<br/>Builds Dashboard 3<br/>Definition C"]
    START --> TEAM4["Data Science<br/>Builds Model<br/>Definition D"]
    
    TEAM1 --> RESULT1["520,000"]
    TEAM2 --> RESULT2["500,000"]
    TEAM3 --> RESULT3["480,000"]
    TEAM4 --> RESULT4["515,000"]
    
    style START fill:#dbeafe,stroke:#2563eb
    style RESULT1 fill:#fee,stroke:#f00
    style RESULT2 fill:#fee,stroke:#f00
    style RESULT3 fill:#fee,stroke:#f00
    style RESULT4 fill:#fee,stroke:#f00
</div>

**What goes wrong:**
1. Each team builds their own dashboard/report
2. Each team makes small, seemingly reasonable choices about how to calculate metrics
3. Over time, these choices diverge
4. Nobody notices until it's too late

---

## The Real Cost of Metric Inconsistency

### Cost 1: Bad Business Decisions

> **The danger:** When executives see different numbers, they make decisions based on wrong data.

**Real scenario:**

```
Marketing meeting:
"Our campaign generated 50,000 bookings!" (using their definition)

Finance meeting later that day:
"Marketing spent $5M but only got 35,000 bookings" (using their definition)

CEO's conclusion:
"Marketing is terrible! Fire the CMO!"

Reality:
Both numbers were "correct" based on different definitions
But the decision to fire CMO was based on inconsistent metrics
```

**The cost:** Billions in bad decisions.

### Cost 2: Wasted Engineering Time

> **The reality:** Engineers spend 50-70% of their time fixing data inconsistencies instead of building features.

**A typical engineer's week:**

```
Monday:
"Why does our dashboard show different numbers than theirs?"
- Investigate: 4 hours
- Root cause: Different SQL query
- Fix: 2 hours

Tuesday:
"Our A/B test results don't match the experiment platform"
- Debug: 6 hours
- Root cause: Different date filters
- Fix: 2 hours

Wednesday:
"Customer support says our metrics are wrong"
- Investigate: 4 hours
- Root cause: Different timezone handling
- Fix: 2 hours

Thursday:
"CEO wants explanation for discrepancy in board deck"
- Urgent investigation: 8 hours
- Root cause: Different definition of "active user"
- Write explanation: 2 hours

Friday:
"Fix production bug"
- Actually build features: 4 hours

Total: 36 hours on metrics issues, 4 hours on features!
That's 90% of time wasted!
```

**At Airbnb scale:**
- 2,000+ data engineers
- 90% time on metrics issues = 1,800 engineers wasted
- Cost: $360M/year in salaries alone!

### Cost 3: Lost Trust in Data

> **The death spiral:** When people see inconsistent numbers, they stop trusting data altogether.

**How trust dies:**

```
Week 1:
Manager: "This dashboard shows 500K bookings"
Analyst: "Actually, this other dashboard shows 480K"
Manager: "Hmm, which is right?"

Week 5:
Manager: "These numbers don't match again"
Analyst: "Let me investigate..."
Manager: "This is getting annoying"

Week 10:
Manager: "I don't trust any of these dashboards anymore"
Analyst: "But this one is correct!"
Manager: "That's what you said about the last three..."

Week 15:
Manager: "I'll just use my gut feeling instead"
Company: *Makes decisions based on intuition, not data*

Result: $1B+ company making decisions with zero data!
```

### Cost 4: Slow Decision Making

> **The bottleneck:** Every meeting becomes a debate about which numbers to trust.

**Before the problem is fixed:**

```
Meeting to decide: "Should we expand to Japan?"

Hour 1: Discussing which metrics to use
- Product: "Based on our data..."
- Marketing: "No, our data shows..."
- Finance: "Actually, according to our numbers..."
- Data Science: "All your numbers are wrong..."

Hour 2: Still debating data quality
- "Why do your numbers differ from mine?"
- "Did you include canceled bookings?"
- "Which timezone are you using?"
- "Are you filtering test accounts?"

Hour 3: Finally getting somewhere
- Everyone recalculates using agreed definition
- Numbers start to align
- But meeting time is up!

Hour 4: Schedule follow-up meeting

Total meetings needed: 5-10
Time to decision: 2-3 months
Cost: Missed market opportunity
```

---

## How Metric Inconsistency Happens

### Problem 1: No Single Source of Truth

> **The issue:** Every team calculates metrics independently.

**Typical company structure:**

```
Marketing Team:
â”œâ”€ Marketing Data Engineer
â”œâ”€ Writes SQL: SELECT COUNT(*) FROM bookings WHERE source='ads'
â”œâ”€ Creates Dashboard: "Marketing Bookings"
â””â”€ Definition lives in their code

Product Team:
â”œâ”€ Product Data Engineer
â”œâ”€ Writes SQL: SELECT COUNT(*) FROM bookings WHERE status='confirmed'
â”œâ”€ Creates Dashboard: "Product Bookings"
â””â”€ Definition lives in their code (different!)

Finance Team:
â”œâ”€ Finance Analyst
â”œâ”€ Writes SQL: SELECT COUNT(*) FROM bookings WHERE payment_status='paid'
â”œâ”€ Creates Report: "Financial Bookings"
â””â”€ Definition lives in their spreadsheet (even more different!)

Result: 3 definitions of "bookings", none documented!
```

### Problem 2: Metric Sprawl

> **The issue:** Metrics multiply like rabbits.

**Airbnb's metric growth:**

```
Year 1 (2008): 10 key metrics
- Bookings, Revenue, Users, etc.
- Everyone uses same definitions
- Life is simple âœ…

Year 5 (2013): 500 metrics
- Different teams create variations
- "Bookings" becomes:
  - Total Bookings
  - New Bookings
  - Repeat Bookings
  - Canceled Bookings
  - Pending Bookings
  - 50 other variations...
- Some documented, most not

Year 10 (2018): 10,000+ metrics
- Nobody knows which is the "official" metric
- Same metric has 10+ different calculations
- Data teams spend all time reconciling
- Complete chaos âŒ

Current state: Unsustainable
```

### Problem 3: Hidden Assumptions

> **The issue:** Every metric calculation makes dozens of hidden assumptions.

**Example: Calculating "Average Booking Value"**

Seems simple: `AVG(booking_price)`

But hidden questions:
```
1. Currency?
   - USD, EUR, JPY, or local currency?
   - What exchange rate?
   - On what date?

2. Time period?
   - Booking date or check-in date?
   - UTC or local timezone?
   - Include today or not?

3. Booking status?
   - Include canceled?
   - Include pending?
   - Include refunded?
   - Include modified?

4. Booking type?
   - Include test bookings?
   - Include employee bookings?
   - Include promotional bookings?
   - Include instant book only?

5. Outliers?
   - Include $100,000 luxury mansions?
   - Include $1 promotional bookings?
   - What's the max/min?

Total combinations: 2^5 = 32+ different calculations!
All called "Average Booking Value"!
```

**At Airbnb:** Each team made different choices, none documented.

### Problem 4: Lack of Lineage Tracking

> **The issue:** When metrics change, nobody knows what broke downstream.

**The cascade of failure:**

<div class="mermaid">
flowchart TD
    BASE["Base Table:<br/>raw_bookings"]
    
    BASE --> M1["Metric 1:<br/>Total Bookings<br/>(used by Dashboard A)"]
    BASE --> M2["Metric 2:<br/>Booking Rate<br/>(used by Dashboard B)"]
    
    M2 --> M3["Metric 3:<br/>Conversion Rate<br/>(used by A/B test)"]
    M3 --> M4["Metric 4:<br/>ROI<br/>(used by CEO dashboard)"]
    
    BASE -.->|"Someone changes<br/>base table definition"| BREAK["ğŸ’¥"]
    
    BREAK -.-> M1
    BREAK -.-> M2
    BREAK -.-> M3
    BREAK -.-> M4
    
    style BASE fill:#dbeafe,stroke:#2563eb
    style BREAK fill:#fee,stroke:#f00
    style M4 fill:#fee,stroke:#f00
</div>

**What happens:**

```
Day 1:
Data Engineer: "I'll improve the raw_bookings table"
- Changes booking_date from PST to UTC
- Seems like a good idea
- No warning systems

Day 2:
Dashboard A: Shows wrong numbers (but nobody notices yet)

Day 3:
Dashboard B: Shows wrong conversion rates
A/B test: Makes wrong decision based on bad data

Day 5:
CEO dashboard: Shows incorrect ROI
CEO: "Why did our performance tank suddenly?"
Everyone: Panic! ğŸ”¥

Day 10:
After investigation:
- 47 downstream metrics were broken
- 130 dashboards showed wrong data
- 12 A/B tests made wrong decisions
- $10M in bad business decisions

Root cause: One small change, no impact tracking
```

### Problem 5: No Version Control for Metrics

> **The issue:** Code has Git, but metrics have nothing.

**Software code (good):**

```
âœ… Every change tracked in Git
âœ… Can see who changed what and when
âœ… Can roll back bad changes
âœ… Can review changes before deploy
âœ… Can see impact of changes

Example:
git log bookings.sql
- June 1: John changed filter logic
- May 15: Sarah updated timezone handling  
- May 1: Mike added new booking types
```

**Metrics at Airbnb (bad):**

```
âŒ No version control
âŒ Metrics defined in various places:
   - SQL queries in dashboards
   - Python scripts on laptops
   - Spreadsheet formulas
   - Jupyter notebooks
   - Slack messages ("Just use this query")
   
âŒ When metric changes:
   - No record of what changed
   - No record of who changed it
   - No record of why it changed
   - Can't roll back
   - Can't review

Result: Complete chaos
```

---

## Real Examples from Airbnb

### Example 1: The "Active User" Disaster

**The question:** "How many active users do we have?"

**What happened:**

```
Product Team definition:
- User who logged in last 30 days
- Result: 50 million active users

Growth Team definition:
- User who searched for listings last 30 days
- Result: 35 million active users

Finance Team definition:
- User who made a booking last 90 days
- Result: 20 million active users

CEO to investors:
"We have 50 million active users!"

Investors do their own analysis:
"Actually, based on Finance data, it's 20 million"

Investor: "Are you lying to us?"
CEO: "No, we just have different definitions!"
Investor: "That's even worse!"

Result: Trust destroyed, stock price drops
```

### Example 2: The A/B Test Catastrophe

**The experiment:** Test new booking flow

**What happened:**

```
Week 1: Launch A/B test
- Hypothesis: New flow will increase bookings by 10%
- Metric used: "Bookings" (Product team definition)
- Result after 1 week: +15% bookings âœ…

Decision: "Ship it to 100% of users!"

Week 2: Rollout to everyone
- Marketing tracks using their "Bookings" metric
- Result: -5% bookings âŒ
- Marketing: "Product team broke bookings!"

Week 3: Investigation
- Product: "Our metric shows +15%"
- Marketing: "Our metric shows -5%"
- Root cause: Different definitions
  - Product counted initiated bookings (up)
  - Marketing counted completed bookings (down)
  - New flow: More initiations, fewer completions
  - Net result: Feature made things worse!

Week 4: Rollback
- Feature removed
- 2 weeks of bad user experience
- Estimated cost: $50M in lost bookings
- All because of metric inconsistency!
```

### Example 3: The Forecasting Failure

**The goal:** Forecast bookings for next quarter

**What happened:**

```
Data Science Team:
- Builds ML model to forecast bookings
- Trains on 2 years of historical data
- Uses "bookings" from data warehouse
- Forecast: 10M bookings next quarter

Reality Check (next quarter):
- Product team: "We hit 11M bookings!"
- Marketing team: "We only got 9.5M bookings"
- Finance team: "Revenue suggests 9M bookings"

Post-mortem:
- Data Science used definition A
- Product used definition B
- Marketing used definition C
- Finance used definition D
- Model was accurate... for definition A
- But business used definition B/C/D
- Forecast appeared wrong (but wasn't!)

Result:
- CFO: "Fire the data science team!"
- Data Science: "Our forecast was correct!"
- CFO: "Then why are we missing targets?"
- Data Science: "Different definitions..."
- CFO: "This is unacceptable!"

Career impact: 3 people left the company
```

---

## The Scale of the Problem

### By the Numbers (Airbnb in 2018)

```
Metrics:
- 10,000+ defined metrics
- 50+ definitions of "bookings" alone
- 100+ definitions of "active user"
- 1,000+ definitions of "revenue"

Teams:
- 200+ data teams
- 2,000+ data engineers
- 5,000+ employees using data daily

Impact:
- 50-70% engineering time on reconciliation
- 100+ hours per week in "metrics meetings"
- $100M+ per year in wasted time
- $500M+ per year in bad decisions

Scalability:
- Problem grows O(NÂ²) with company size
- More teams = exponentially more inconsistency
- Unsustainable!
```

### The Breaking Point

**Airbnb's "Oh Shit" moment (2018):**

```
Situation:
- Preparing for IPO
- Auditors reviewing financial metrics
- Need to certify accuracy

Auditor: "What's your 2017 revenue?"

Airbnb: "We have 5 different answers"
  - Finance: $2.6B
  - Product: $2.8B
  - Data warehouse: $2.7B
  - Tax team: $2.5B
  - CEO's dashboard: $2.9B

Auditor: "Which is correct?"

Airbnb: "Uh... all of them?"

Auditor: "I can't certify this. Fix it or no IPO."

CEO: "Drop everything. Fix this NOW."

Result: Emergency project launched
```

---

## Why This Problem is Universal

### It's Not Just Airbnb

**Companies with the same problem:**

```
Small Startup (50 employees):
- 3-5 definitions of key metrics
- Weekly arguments about numbers
- Cost: 20% of engineering time

Mid-Size Company (500 employees):
- 50-100 definitions per metric
- Daily confusion
- Cost: 40% of engineering time

Large Enterprise (5,000+ employees):
- 1,000+ definitions per metric
- Complete chaos
- Cost: 60-70% of engineering time

Every company hits this eventually!
```

### Why It Always Happens

```
Phase 1: Startup (0-50 people)
â”œâ”€ Everyone sits together
â”œâ”€ Informal communication works
â”œâ”€ One person knows all metrics
â””â”€ No problem yet âœ…

Phase 2: Growth (50-200 people)
â”œâ”€ Teams start to specialize
â”œâ”€ Each team builds own dashboards
â”œâ”€ Small differences emerge
â””â”€ Minor annoyance ğŸ˜

Phase 3: Scale (200-1,000 people)
â”œâ”€ Teams in different locations
â”œâ”€ Can't talk to everyone
â”œâ”€ Metrics diverge significantly
â””â”€ Major problem ğŸ˜°

Phase 4: Enterprise (1,000+ people)
â”œâ”€ Multiple business units
â”œâ”€ Acquisitions add more systems
â”œâ”€ Complete metric chaos
â””â”€ Crisis! ğŸ”¥

The bigger you get, the worse it gets!
```

---

## The Traditional "Solutions" (That Don't Work)

### Failed Solution 1: "Let's Document Everything"

**The approach:**
```
Week 1: Create "Metrics Wiki"
- Document all 10,000 metrics
- Define each one carefully
- Get everyone to read it

Week 5: Wiki has 100 pages
- But metrics keep changing
- Documentation out of date

Week 10: Wiki has 500 pages
- Nobody reads it
- Too much text
- Still inconsistent

Result: $500K spent, zero impact âŒ
```

### Failed Solution 2: "Let's Have a Metrics Team"

**The approach:**
```
Hire "Metrics Team" to enforce standards

Month 1: Team defines standards
- "All metrics must use UTC"
- "All metrics must document assumptions"
- Etc.

Month 3: Nobody follows standards
- Too slow to wait for approval
- Engineers bypass the process
- Metrics team becomes bottleneck

Month 6: Metrics team overwhelmed
- 100+ requests per week
- Can't review everything
- Standards ignored

Result: Created bureaucracy, didn't solve problem âŒ
```

### Failed Solution 3: "Let's Build a Dashboard Tool"

**The approach:**
```
Build internal BI tool with "standardized metrics"

Year 1: Build tool
- $5M investment
- 20 engineers
- Looks great!

Year 2: Launch
- But... teams still use their own SQL
- Tool too rigid for custom analysis
- Adoption: 30%

Year 3: Failure
- 70% of users still use custom queries
- Tool becomes yet another source of inconsistency
- Problem actually worse (now one more tool!)

Result: $15M wasted âŒ
```

### Failed Solution 4: "Let's Just Talk More"

**The approach:**
```
"Everyone meet weekly to align on metrics"

Week 1: Meeting with 50 people
- Takes 2 hours
- Align on "bookings" definition
- Everyone agrees âœ…

Week 2: Already diverging
- Product: "We need to add one small filter..."
- Marketing: "For our use case, we should..."
- Definitions drift immediately

Week 10: Back to chaos
- Nobody remembers the meeting
- Everyone has their own definition again
- Meetings become pointless

Result: 100 hours wasted per week âŒ
```

---

## What Airbnb Realized

### The Key Insight

> **The problem isn't people, it's systems.**
> 
> You can't solve metric consistency with documentation, meetings, or teams.
> You need a platform that makes inconsistency impossible.

**The realization:**

```
Old thinking:
"We need to educate people to use metrics correctly"

New thinking:
"We need to make it impossible to use metrics incorrectly"

Old approach:
- Document metrics
- Train people
- Review code
- Hope for the best

New approach:
- Define metrics once, in code
- Make everyone use the same code
- Automate verification
- Enforce consistency
```

### The Requirements for a Real Solution

**What Airbnb needed:**

```
1. Single Source of Truth
   âœ… One place to define each metric
   âœ… Everyone uses the same definition
   âœ… No way to bypass it

2. Version Control
   âœ… Track every change
   âœ… See who, what, when, why
   âœ… Roll back if needed

3. Impact Analysis
   âœ… Know what breaks when you change something
   âœ… Alert affected teams
   âœ… Prevent accidents

4. Automatic Propagation
   âœ… Change metric once
   âœ… Updates everywhere automatically
   âœ… No manual work

5. Testing Environment
   âœ… Test changes before production
   âœ… Verify correctness
   âœ… Zero downtime

6. Developer Friendly
   âœ… Easy to use
   âœ… Fast iteration
   âœ… Doesn't slow teams down
```

---

## The Bottom Line

### Why This Matters

**Metric consistency is not a "nice to have" â€” it's essential for:**

1. **Making good decisions**
   - Wrong metrics = wrong decisions
   - Cost: Billions

2. **Moving fast**
   - Inconsistent metrics slow everything down
   - Cost: Opportunity cost

3. **Trusting data**
   - Without trust, data is useless
   - Cost: Company makes gut decisions

4. **Engineering productivity**
   - Stop wasting time reconciling numbers
   - Cost: 50-70% of engineering time

5. **IPO readiness**
   - Auditors require metric consistency
   - Cost: Can't go public without it

### The Challenge

**Building a solution is hard:**

```
Requirements:
âœ… Must work at massive scale (10,000+ metrics)
âœ… Must be developer-friendly (or nobody uses it)
âœ… Must be performant (can't slow queries down)
âœ… Must be flexible (support all use cases)
âœ… Must be reliable (can't break production)

Constraints:
âŒ Can't disrupt existing systems (too risky)
âŒ Can't force everyone to migrate at once (impossible)
âŒ Can't slow down teams (they'll bypass it)
âŒ Can't be expensive to maintain (not sustainable)

Challenge: Build all this while company is rapidly growing!
```

---

## What's Next?

In Part 2, we'll see how Airbnb built **Minerva** â€” a platform that solved all these problems:

**Sneak peek of the solution:**

```
Minerva Platform:
â”œâ”€ Single source of truth for all metrics
â”œâ”€ Git-like version control
â”œâ”€ Automatic impact analysis
â”œâ”€ Staging environment for testing
â”œâ”€ Automatic data backfilling
â””â”€ Zero downtime updates

Results:
âœ… From 10,000 inconsistent metrics to 10,000 consistent metrics
âœ… From 70% time on reconciliation to 10%
âœ… From chaos to clarity
âœ… From blocks to IPO

Engineering time saved: 60%
Bad decisions prevented: $500M+/year
Time to implement: 2 years
```

**Continue to:** [Part 2 - The Solution (Building Minerva) â†’]({{ site.baseurl }}{% link _topics/airbnb-metric-consistency-part-2-solution.md %})

---

## Summary: The Metric Consistency Crisis

### The Problem in One Picture

```
The Question: "How many bookings yesterday?"

Before:
â”œâ”€ Product: 520,000
â”œâ”€ Marketing: 500,000
â”œâ”€ Finance: 480,000
â”œâ”€ Data Science: 515,000
â””â”€ CEO: "...which one?!"

After (with Minerva):
â”œâ”€ Everyone: 500,000
â”œâ”€ All dashboards: 500,000
â”œâ”€ All reports: 500,000
â””â”€ CEO: "Finally!" âœ…
```

### Key Takeaways

1. **Metric inconsistency is the silent killer**
   - Not a technical problem, a business problem
   - Costs billions in bad decisions

2. **It happens to everyone**
   - Small startups to big enterprises
   - Gets worse as you grow

3. **Traditional solutions don't work**
   - Documentation, meetings, teams all fail
   - Need a platform solution

4. **The real cost is trust**
   - Without consistent metrics, data is useless
   - Companies fall back to gut decisions

5. **Airbnb solved it**
   - Built Minerva platform
   - Saved 60% of engineering time
   - Enabled IPO

**Next:** Learn exactly how they did it! â†’ [Part 2]({{ site.baseurl }}{% link _topics/airbnb-metric-consistency-part-2-solution.md %})

---

## Further Reading

- **[Airbnb Engineering Blog](https://medium.com/airbnb-engineering)** - Original articles and case studies
- **[Original Airbnb Minerva Article](https://medium.com/airbnb-engineering/how-airbnb-achieved-metric-consistency-at-scale-f23cc53dea70)** - The source article
- **[Data Quality at Scale](https://www.oreilly.com/library/view/data-quality-at/9781492063742/)** - Book on data quality
- **[dbt: Metrics as Code](https://www.getdbt.com/blog/how-do-you-build-a-metrics-layer)** - Similar approach
- **[The Data Warehouse Toolkit](https://www.amazon.com/Data-Warehouse-Toolkit-Definitive-Dimensional/dp/1118530802)** - Dimensional modeling