<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Scaling Your API: Part 1 - Performance & Infrastructure</title>
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="icon" href="/handbook/assets/img/logo.svg" type="image/svg+xml">
    <link rel="stylesheet" href="/handbook/assets/css/style.css">
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <div class="site-brand">
          <a href="/handbook/" class="brand-link">
            <img src="/handbook/assets/img/logo.svg" alt="Handbook logo" width="36" height="36" />
          </a>
          <div>
            <h1><a href="/handbook/">Handbook</a></h1>
            <p class="site-desc">Quick tech ticks and comparisons</p>
          </div>
        </div>
        <nav class="site-nav" aria-label="Main">
          <a href="/handbook/">Home</a>
          <a href="/handbook/#categories">Categories</a>
          <a href="/handbook/about">About</a>
          <a href="https://github.com/rilov" target="_blank" rel="noopener">GitHub</a>
        </nav>
      </div>
    </header>

    <main class="container">
      <article class="topic">
  <header>
    <nav class="breadcrumb small">
      <a href="/handbook/">Home</a> &mdash;
      <a href="/handbook/categories/architecture">Architecture</a> &mdash;
    </nav>
    <h2>Scaling Your API: Part 1 - Performance & Infrastructure</h2>
    
      
      <p class="meta">Category: <a href="/handbook/categories/architecture">Architecture</a></p>
    
  </header>

  <section class="topic-body">
    <blockquote>
  <p><strong>ğŸ“š This is Part 1 of a two-part series on API Scaling</strong></p>
  <ul>
    <li><strong>Part 1 (this page):</strong> Performance &amp; Infrastructure - Technical techniques to handle millions of requests</li>
    <li><strong><a href="/handbook/handbook/_topics/scaling-api-design-architecture-part-2/">Part 2: Design &amp; Architecture â†’</a></strong> - Organizational strategies and API design patterns for large-scale systems</li>
  </ul>
</blockquote>

<h2 id="the-journey-1-rps--1000000-rps">The Journey: 1 RPS â†’ 1,000,000 RPS</h2>

<p>Imagine your API is a restaurant. At first, you have one chef (server) handling one order at a time. But what happens when you go viral and suddenly have a million customers waiting?</p>

<div class="mermaid">
flowchart LR
    subgraph before["ğŸ˜° Before Scaling"]
        U1["ğŸ‘¤ User"] --&gt; S1["ğŸ–¥ï¸ 1 Server"]
        S1 --&gt; D1["ğŸ—„ï¸ 1 Database"]
    end
    
    subgraph after["ğŸ˜ After Scaling"]
        U2["ğŸ‘¥ Millions<br />of Users"] --&gt; LB["âš–ï¸ Load<br />Balancer"]
        LB --&gt; S2["ğŸ–¥ï¸ Server 1"]
        LB --&gt; S3["ğŸ–¥ï¸ Server 2"]
        LB --&gt; S4["ğŸ–¥ï¸ Server N..."]
        S2 --&gt; C["âš¡ Cache"]
        S3 --&gt; C
        S4 --&gt; C
        C --&gt; DB["ğŸ—„ï¸ Database<br />Cluster"]
    end
</div>

<hr />

<h2 id="overview-the-14-key-scaling-techniques">Overview: The 14 Key Scaling Techniques</h2>

<p>Scaling an API isnâ€™t about implementing all techniques at onceâ€”itâ€™s about choosing the right tools for your current stage. This guide covers 14 proven techniques in order of complexity:</p>

<h3 id="foundation-must-haves-for-every-api">Foundation (Must-Haves for Every API)</h3>
<ol>
  <li><strong>Vertical Scaling</strong> - Start here: upgrade your single serverâ€™s resources</li>
  <li><strong>Connection Pooling</strong> - Reuse database connections instead of opening new ones</li>
  <li><strong>Avoid N+1 Queries</strong> - Fetch related data efficiently with joins</li>
</ol>

<h3 id="essential-optimizations-1-10k-rps">Essential Optimizations (1-10K RPS)</h3>
<ol>
  <li><strong>Horizontal Scaling</strong> - Add more servers to distribute the load</li>
  <li><strong>Load Balancing</strong> - Intelligently route traffic across servers</li>
  <li><strong>Caching</strong> - Store frequently accessed data in memory (Redis/Memcached)</li>
  <li><strong>Pagination</strong> - Send data in manageable chunks instead of all at once</li>
</ol>

<h3 id="performance-enhancements-10k-100k-rps">Performance Enhancements (10K-100K RPS)</h3>
<ol>
  <li><strong>Fast JSON Serializers</strong> - Use optimized libraries for data serialization</li>
  <li><strong>Compression</strong> - Reduce payload sizes with Gzip or Brotli</li>
  <li><strong>CDN</strong> - Serve content from edge servers close to users</li>
  <li><strong>Async Processing</strong> - Move slow tasks to background workers</li>
</ol>

<h3 id="advanced-scaling-100k-rps">Advanced Scaling (100K+ RPS)</h3>
<ol>
  <li><strong>Async Logging</strong> - Make logging non-blocking</li>
  <li><strong>Database Sharding</strong> - Split your database horizontally</li>
  <li><strong>Rate Limiting</strong> - Protect your system from abuse</li>
</ol>

<h3 id="the-three-critical-insights">The Three Critical Insights</h3>

<p><strong>1. Start Simple, Scale Progressively</strong>
Donâ€™t build for 1M RPS on day one. A single well-optimized server can handle 10,000+ RPS with proper caching and database optimization.</p>

<p><strong>2. Fix the Bottleneck, Not Everything</strong>
Measure your system to identify the actual bottleneck (CPU? Memory? Database? Network?) and address that specific issue first.</p>

<p><strong>3. Some Techniques Are Always Worth It</strong>
Connection pooling, avoiding N+1 queries, basic caching, pagination, and compression should be implemented from the startâ€”theyâ€™re simple and have massive impact.</p>

<p>Letâ€™s dive into each technique in detail, starting from the simplest to the most advanced.</p>

<hr />

<h2 id="level-1-vertical-scaling-the-easy-start">Level 1: Vertical Scaling (The Easy Start)</h2>

<h3 id="what-is-it">What is it?</h3>

<p>Make your single server bigger and more powerful â€” more CPU, more RAM, faster disk.</p>

<div class="mermaid">
flowchart LR
    subgraph before["Before"]
        A["ğŸ–¥ï¸ Small Server<br />2 CPU, 4GB RAM"]
    end
    
    subgraph after["After"]
        B["ğŸ–¥ï¸ Big Server<br />32 CPU, 128GB RAM"]
    end
    
    before --&gt;|ğŸ’° Upgrade| after
    
    style A fill:#fecaca,stroke:#dc2626
    style B fill:#d1fae5,stroke:#059669
</div>

<h3 id="real-world-analogy">Real-World Analogy</h3>

<p>Instead of hiring more chefs, you give your one chef a bigger kitchen with better equipment.</p>

<h3 id="limits">Limits</h3>

<ul>
  <li>âŒ Thereâ€™s a ceiling â€” servers can only get so big</li>
  <li>âŒ Single point of failure â€” if it crashes, everything goes down</li>
  <li>âŒ Expensive at the top end</li>
</ul>

<p><strong>Good for:</strong> 1 â†’ 100 RPS</p>

<hr />

<h2 id="level-2-horizontal-scaling-add-more-servers">Level 2: Horizontal Scaling (Add More Servers)</h2>

<h3 id="what-is-it-1">What is it?</h3>

<p>Instead of one big server, use many smaller servers working together.</p>

<div class="mermaid">
flowchart TD
    U["ğŸ‘¥ Users"] --&gt; LB["âš–ï¸ Load Balancer"]
    LB --&gt; S1["ğŸ–¥ï¸ Server 1"]
    LB --&gt; S2["ğŸ–¥ï¸ Server 2"]
    LB --&gt; S3["ğŸ–¥ï¸ Server 3"]
    LB --&gt; S4["ğŸ–¥ï¸ Server 4"]
    
    style LB fill:#dbeafe,stroke:#2563eb
    style S1 fill:#d1fae5,stroke:#059669
    style S2 fill:#d1fae5,stroke:#059669
    style S3 fill:#d1fae5,stroke:#059669
    style S4 fill:#d1fae5,stroke:#059669
</div>

<h3 id="real-world-analogy-1">Real-World Analogy</h3>

<p>Hire more chefs! Each chef can work independently, handling their own orders.</p>

<h3 id="benefits">Benefits</h3>

<ul>
  <li>âœ… No ceiling â€” just add more servers</li>
  <li>âœ… No single point of failure â€” if one dies, others keep working</li>
  <li>âœ… Cost-effective â€” use cheaper commodity hardware</li>
</ul>

<p><strong>Good for:</strong> 100 â†’ 10,000 RPS</p>

<hr />

<h2 id="level-3-load-balancing-traffic-cop">Level 3: Load Balancing (Traffic Cop)</h2>

<h3 id="what-is-it-2">What is it?</h3>

<p>A load balancer distributes incoming requests across multiple servers evenly.</p>

<div class="mermaid">
flowchart TD
    subgraph clients["Incoming Requests"]
        R1["Request 1"]
        R2["Request 2"]
        R3["Request 3"]
        R4["Request 4"]
        R5["Request 5"]
        R6["Request 6"]
    end
    
    R1 --&gt; LB
    R2 --&gt; LB
    R3 --&gt; LB
    R4 --&gt; LB
    R5 --&gt; LB
    R6 --&gt; LB
    
    LB["âš–ï¸ Load Balancer"]
    
    LB --&gt;|1, 4| S1["ğŸ–¥ï¸ Server 1"]
    LB --&gt;|2, 5| S2["ğŸ–¥ï¸ Server 2"]
    LB --&gt;|3, 6| S3["ğŸ–¥ï¸ Server 3"]
    
    style LB fill:#fef3c7,stroke:#d97706
</div>

<h3 id="common-algorithms">Common Algorithms</h3>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th>How it Works</th>
      <th>Best For</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Round Robin</strong></td>
      <td>Takes turns: 1â†’2â†’3â†’1â†’2â†’3</td>
      <td>Equal server capacity</td>
    </tr>
    <tr>
      <td><strong>Least Connections</strong></td>
      <td>Sends to server with fewest active requests</td>
      <td>Varying request times</td>
    </tr>
    <tr>
      <td><strong>IP Hash</strong></td>
      <td>Same user always goes to same server</td>
      <td>Session persistence</td>
    </tr>
    <tr>
      <td><strong>Weighted</strong></td>
      <td>Stronger servers get more traffic</td>
      <td>Mixed server sizes</td>
    </tr>
  </tbody>
</table>

<h3 id="real-world-analogy-2">Real-World Analogy</h3>

<p>A host at a restaurant who seats customers at different tables to keep all waiters equally busy.</p>

<hr />

<h2 id="level-4-database-connection-pooling">Level 4: Database Connection Pooling</h2>

<h3 id="what-is-it-3">What is it?</h3>

<p>Instead of opening a new database connection for every request, maintain a pool of ready-to-use connections that can be reused.</p>

<div class="mermaid">
sequenceDiagram
    participant R1 as ğŸ“¨ Request 1
    participant R2 as ğŸ“¨ Request 2
    participant R3 as ğŸ“¨ Request 3
    participant P as ğŸŠ Connection Pool
    participant DB as ğŸ—„ï¸ Database
    
    Note over P,DB: Pool has 3 connections ready
    
    R1-&gt;&gt;P: Need connection
    P-&gt;&gt;R1: âœ… Connection #1
    R1-&gt;&gt;DB: Query
    
    R2-&gt;&gt;P: Need connection
    P-&gt;&gt;R2: âœ… Connection #2
    R2-&gt;&gt;DB: Query
    
    R3-&gt;&gt;P: Need connection
    P-&gt;&gt;R3: âœ… Connection #3
    R3-&gt;&gt;DB: Query
    
    R1-&gt;&gt;P: Done! Return connection
    Note over P: Connection #1 back in pool
    
    R2-&gt;&gt;P: Done! Return connection
    R3-&gt;&gt;P: Done! Return connection
</div>

<h3 id="why-it-matters">Why It Matters</h3>

<p>Opening a database connection is expensive:</p>

<table>
  <thead>
    <tr>
      <th>Action</th>
      <th>Time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Open new connection</td>
      <td>50-100ms</td>
    </tr>
    <tr>
      <td>Reuse from pool</td>
      <td>&lt; 1ms</td>
    </tr>
  </tbody>
</table>

<p>With 1000 requests/sec, you save <strong>50-100 seconds</strong> of work!</p>

<h3 id="without-vs-with-connection-pooling">Without vs With Connection Pooling</h3>

<div class="mermaid">
flowchart TD
    subgraph without["âŒ Without Pooling (Slow)"]
        direction TB
        S1["Request"] --&gt; O1["Open connection<br />50ms"]
        O1 --&gt; Q1["Query<br />10ms"]
        Q1 --&gt; C1["Close connection<br />5ms"]
        C1 --&gt; T1["Total: 65ms"]
    end
    
    subgraph with["âœ… With Pooling (Fast)"]
        direction TB
        S2["Request"] --&gt; G2["Get from pool<br />&lt; 1ms"]
        G2 --&gt; Q2["Query<br />10ms"]
        Q2 --&gt; R2["Return to pool<br />&lt; 1ms"]
        R2 --&gt; T2["Total: 12ms"]
    end
    
    style without fill:#fecaca,stroke:#dc2626
    style with fill:#d1fae5,stroke:#059669
</div>

<h3 id="real-world-analogy-3">Real-World Analogy</h3>

<p>Instead of getting a new fork for every bite of food, you keep your fork and reuse it throughout the meal.</p>

<h3 id="implementation-tips">Implementation Tips</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Python example with connection pooling
</span><span class="kn">from</span> <span class="n">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>

<span class="c1"># Create engine with connection pool
</span><span class="n">engine</span> <span class="o">=</span> <span class="nf">create_engine</span><span class="p">(</span>
    <span class="sh">'</span><span class="s">postgresql://user:pass@localhost/db</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">pool_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>           <span class="c1"># Keep 20 connections ready
</span>    <span class="n">max_overflow</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>        <span class="c1"># Allow 10 more if needed
</span>    <span class="n">pool_pre_ping</span><span class="o">=</span><span class="bp">True</span>      <span class="c1"># Check if connection is alive
</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Good for:</strong> All production APIs with databases</p>

<hr />

<h2 id="level-5-avoiding-n1-query-problems">Level 5: Avoiding N+1 Query Problems</h2>

<h3 id="what-is-it-4">What is it?</h3>

<p>The N+1 problem happens when you fetch a list of items, then make a separate query for each itemâ€™s related data. This turns 1 query into N+1 queries!</p>

<div class="mermaid">
sequenceDiagram
    participant A as ğŸ–¥ï¸ API
    participant DB as ğŸ—„ï¸ Database
    
    Note over A,DB: âŒ N+1 Problem (10 queries!)
    
    A-&gt;&gt;DB: Get all users (1 query)
    DB--&gt;&gt;A: User 1, User 2, User 3
    
    A-&gt;&gt;DB: Get posts for User 1
    A-&gt;&gt;DB: Get posts for User 2
    A-&gt;&gt;DB: Get posts for User 3
    A-&gt;&gt;DB: Get comments for Post 1
    A-&gt;&gt;DB: Get comments for Post 2
    A-&gt;&gt;DB: Get comments for Post 3
    A-&gt;&gt;DB: Get likes for Post 1
    A-&gt;&gt;DB: Get likes for Post 2
    A-&gt;&gt;DB: Get likes for Post 3
    
    Note over A,DB: Total: 10 queries, 500ms
</div>

<h3 id="the-better-way-join-or-batch-queries">The Better Way: Join or Batch Queries</h3>

<div class="mermaid">
sequenceDiagram
    participant A as ğŸ–¥ï¸ API
    participant DB as ğŸ—„ï¸ Database
    
    Note over A,DB: âœ… Optimized (1-2 queries!)
    
    A-&gt;&gt;DB: Get users with posts and comments<br />(using JOIN)
    DB--&gt;&gt;A: All data in one result
    
    Note over A,DB: Total: 1 query, 50ms
</div>

<h3 id="problem-example">Problem Example</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># âŒ BAD: N+1 Problem
</span><span class="n">users</span> <span class="o">=</span> <span class="n">User</span><span class="p">.</span><span class="n">query</span><span class="p">.</span><span class="nf">all</span><span class="p">()</span>  <span class="c1"># 1 query
</span>
<span class="k">for</span> <span class="n">user</span> <span class="ow">in</span> <span class="n">users</span><span class="p">:</span>  <span class="c1"># 100 users
</span>    <span class="n">posts</span> <span class="o">=</span> <span class="n">user</span><span class="p">.</span><span class="n">posts</span>  <span class="c1"># 100 more queries!
</span>    <span class="c1"># Total: 101 queries
</span></code></pre></div></div>

<h3 id="solution-example">Solution Example</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># âœ… GOOD: Eager Loading
</span><span class="n">users</span> <span class="o">=</span> <span class="n">User</span><span class="p">.</span><span class="n">query</span><span class="p">.</span><span class="nf">options</span><span class="p">(</span>
    <span class="nf">joinedload</span><span class="p">(</span><span class="n">User</span><span class="p">.</span><span class="n">posts</span><span class="p">)</span>
<span class="p">).</span><span class="nf">all</span><span class="p">()</span>  <span class="c1"># Just 1 query with JOIN!
</span>
<span class="k">for</span> <span class="n">user</span> <span class="ow">in</span> <span class="n">users</span><span class="p">:</span>
    <span class="n">posts</span> <span class="o">=</span> <span class="n">user</span><span class="p">.</span><span class="n">posts</span>  <span class="c1"># No additional query!
</span></code></pre></div></div>

<h3 id="performance-impact">Performance Impact</h3>

<div class="mermaid">
flowchart LR
    subgraph problem["âŒ N+1 Problem"]
        direction TB
        P1["100 users"]
        P2["101 queries"]
        P3["2000ms response"]
    end
    
    subgraph solution["âœ… Optimized"]
        direction TB
        S1["100 users"]
        S2["1-2 queries"]
        S3["50ms response"]
    end
    
    problem --&gt;|40x faster| solution
    
    style problem fill:#fecaca,stroke:#dc2626
    style solution fill:#d1fae5,stroke:#059669
</div>

<h3 id="real-world-analogy-4">Real-World Analogy</h3>

<p>Instead of making 100 trips to the store to buy 100 items, you make one trip with a shopping list and get everything at once.</p>

<p><strong>Good for:</strong> Any API that returns lists with related data</p>

<hr />

<h2 id="level-6-caching-remember--reuse">Level 6: Caching (Remember &amp; Reuse)</h2>

<h3 id="what-is-it-5">What is it?</h3>

<p>Store frequently accessed data in fast memory so you donâ€™t have to compute or fetch it again.</p>

<div class="mermaid">
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant S as ğŸ–¥ï¸ Server
    participant C as âš¡ Cache (Redis)
    participant D as ğŸ—„ï¸ Database
    
    Note over U,D: First Request (Cache Miss)
    U-&gt;&gt;S: GET /user/123
    S-&gt;&gt;C: Check cache
    C--&gt;&gt;S: âŒ Not found
    S-&gt;&gt;D: Query database
    D--&gt;&gt;S: User data
    S-&gt;&gt;C: Store in cache
    S--&gt;&gt;U: Response (200ms)
    
    Note over U,D: Second Request (Cache Hit)
    U-&gt;&gt;S: GET /user/123
    S-&gt;&gt;C: Check cache
    C--&gt;&gt;S: âœ… Found!
    S--&gt;&gt;U: Response (5ms) ğŸš€
</div>

<h3 id="types-of-caching">Types of Caching</h3>

<div class="mermaid">
flowchart LR
    subgraph layers["Caching Layers"]
        direction TB
        B["ğŸŒ Browser Cache<br />Client-side"]
        CDN["ğŸ“¡ CDN Cache<br />Edge servers"]
        APP["âš¡ App Cache<br />Redis/Memcached"]
        DB["ğŸ—„ï¸ DB Cache<br />Query cache"]
    end
    
    B --&gt; CDN --&gt; APP --&gt; DB
    
    style B fill:#dbeafe,stroke:#2563eb
    style CDN fill:#d1fae5,stroke:#059669
    style APP fill:#fef3c7,stroke:#d97706
    style DB fill:#fce7f3,stroke:#db2777
</div>

<h3 id="what-to-cache">What to Cache</h3>

<ul>
  <li>âœ… API responses that donâ€™t change often</li>
  <li>âœ… Database query results</li>
  <li>âœ… Session data</li>
  <li>âœ… Computed values (totals, aggregations)</li>
</ul>

<h3 id="real-world-analogy-5">Real-World Analogy</h3>

<p>A chef who preps ingredients in advance. Instead of chopping onions for every order, they chop a big batch and grab from it.</p>

<p><strong>Good for:</strong> 1,000 â†’ 100,000 RPS</p>

<hr />

<h2 id="level-7-pagination-send-data-in-chunks">Level 7: Pagination (Send Data in Chunks)</h2>

<h3 id="what-is-it-6">What is it?</h3>

<p>Instead of returning thousands of records at once, break them into small pages that load quickly.</p>

<div class="mermaid">
sequenceDiagram
    participant C as ğŸ‘¤ Client
    participant A as ğŸ–¥ï¸ API
    participant D as ğŸ—„ï¸ Database
    
    Note over C,D: âŒ Without Pagination
    C-&gt;&gt;A: GET /users
    A-&gt;&gt;D: SELECT * FROM users
    D--&gt;&gt;A: 10,000 records (5MB)
    A--&gt;&gt;C: Response takes 5 seconds ğŸ˜´
    
    Note over C,D: âœ… With Pagination
    C-&gt;&gt;A: GET /users?page=1&amp;limit=20
    A-&gt;&gt;D: SELECT * FROM users<br />LIMIT 20 OFFSET 0
    D--&gt;&gt;A: 20 records (10KB)
    A--&gt;&gt;C: Response takes 50ms ğŸš€
</div>

<h3 id="common-pagination-approaches">Common Pagination Approaches</h3>

<div class="mermaid">
flowchart TD
    subgraph offset["Offset-Based"]
        direction TB
        O1["Page 1: OFFSET 0, LIMIT 20"]
        O2["Page 2: OFFSET 20, LIMIT 20"]
        O3["Page 3: OFFSET 40, LIMIT 20"]
    end
    
    subgraph cursor["Cursor-Based (Better!)"]
        direction TB
        C1["Page 1: id &gt; 0, LIMIT 20"]
        C2["Page 2: id &gt; 20, LIMIT 20"]
        C3["Page 3: id &gt; 40, LIMIT 20"]
    end
    
    style offset fill:#fef3c7,stroke:#d97706
    style cursor fill:#d1fae5,stroke:#059669
</div>

<h3 id="implementation">Implementation</h3>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Offset-based pagination (simple but slower for large offsets)</span>
<span class="nx">GET</span> <span class="o">/</span><span class="nx">api</span><span class="o">/</span><span class="nx">users</span><span class="p">?</span><span class="nx">page</span><span class="o">=</span><span class="mi">1</span><span class="o">&amp;</span><span class="nx">limit</span><span class="o">=</span><span class="mi">20</span>

<span class="c1">// Cursor-based pagination (faster, handles real-time changes)</span>
<span class="nx">GET</span> <span class="o">/</span><span class="nx">api</span><span class="o">/</span><span class="nx">users</span><span class="p">?</span><span class="nx">cursor</span><span class="o">=</span><span class="nx">abc123</span><span class="o">&amp;</span><span class="nx">limit</span><span class="o">=</span><span class="mi">20</span>
</code></pre></div></div>

<h3 id="response-format">Response Format</h3>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"data"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="err">...</span><span class="p">],</span><span class="w">
  </span><span class="nl">"pagination"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"total"</span><span class="p">:</span><span class="w"> </span><span class="mi">10000</span><span class="p">,</span><span class="w">
    </span><span class="nl">"page"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
    </span><span class="nl">"limit"</span><span class="p">:</span><span class="w"> </span><span class="mi">20</span><span class="p">,</span><span class="w">
    </span><span class="nl">"total_pages"</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span><span class="p">,</span><span class="w">
    </span><span class="nl">"next_cursor"</span><span class="p">:</span><span class="w"> </span><span class="s2">"xyz789"</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="real-world-analogy-6">Real-World Analogy</h3>

<p>Instead of downloading an entire encyclopedia, you download one page at a time as you read it.</p>

<p><strong>Good for:</strong> Any endpoint that returns lists or collections</p>

<hr />

<h2 id="level-8-lightweight-json-serializers">Level 8: Lightweight JSON Serializers</h2>

<h3 id="what-is-it-7">What is it?</h3>

<p>JSON serialization (converting data structures to JSON) can be a bottleneck. Fast serializers can be 2-10x faster than default ones.</p>

<div class="mermaid">
flowchart LR
    subgraph slow["âŒ Default Serializer"]
        direction TB
        D1["Python dict"]
        D2["json.dumps()"]
        D3["100ms"]
    end
    
    subgraph fast["âœ… Fast Serializer"]
        direction TB
        F1["Python dict"]
        F2["orjson.dumps()"]
        F3["10ms"]
    end
    
    slow --&gt;|10x faster| fast
    
    style slow fill:#fecaca,stroke:#dc2626
    style fast fill:#d1fae5,stroke:#059669
</div>

<h3 id="performance-comparison">Performance Comparison</h3>

<table>
  <thead>
    <tr>
      <th>Language</th>
      <th>Default</th>
      <th>Fast Library</th>
      <th>Speedup</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Python</td>
      <td><code class="language-plaintext highlighter-rouge">json</code></td>
      <td><code class="language-plaintext highlighter-rouge">orjson</code> or <code class="language-plaintext highlighter-rouge">ujson</code></td>
      <td>5-10x</td>
    </tr>
    <tr>
      <td>Node.js</td>
      <td><code class="language-plaintext highlighter-rouge">JSON.stringify()</code></td>
      <td><code class="language-plaintext highlighter-rouge">fast-json-stringify</code></td>
      <td>2-3x</td>
    </tr>
    <tr>
      <td>Java</td>
      <td><code class="language-plaintext highlighter-rouge">Jackson</code></td>
      <td><code class="language-plaintext highlighter-rouge">Jackson</code> (already fast!)</td>
      <td>-</td>
    </tr>
    <tr>
      <td>Go</td>
      <td><code class="language-plaintext highlighter-rouge">encoding/json</code></td>
      <td><code class="language-plaintext highlighter-rouge">jsoniter</code></td>
      <td>3-4x</td>
    </tr>
  </tbody>
</table>

<h3 id="example-implementation">Example Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># âŒ Default (slower)
</span><span class="kn">import</span> <span class="n">json</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># âœ… Fast serializer
</span><span class="kn">import</span> <span class="n">orjson</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">orjson</span><span class="p">.</span><span class="nf">dumps</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>  <span class="c1"># 5-10x faster!
</span></code></pre></div></div>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// âŒ Default (slower)</span>
<span class="kd">const</span> <span class="nx">json</span> <span class="o">=</span> <span class="nx">JSON</span><span class="p">.</span><span class="nf">stringify</span><span class="p">(</span><span class="nx">data</span><span class="p">);</span>

<span class="c1">// âœ… Fast serializer with schema</span>
<span class="kd">const</span> <span class="nx">fastJson</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">fast-json-stringify</span><span class="dl">'</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">stringify</span> <span class="o">=</span> <span class="nf">fastJson</span><span class="p">({</span>
  <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">object</span><span class="dl">'</span><span class="p">,</span>
  <span class="na">properties</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">name</span><span class="p">:</span> <span class="p">{</span> <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">string</span><span class="dl">'</span> <span class="p">},</span>
    <span class="na">age</span><span class="p">:</span> <span class="p">{</span> <span class="na">type</span><span class="p">:</span> <span class="dl">'</span><span class="s1">integer</span><span class="dl">'</span> <span class="p">}</span>
  <span class="p">}</span>
<span class="p">});</span>
<span class="kd">const</span> <span class="nx">json</span> <span class="o">=</span> <span class="nf">stringify</span><span class="p">(</span><span class="nx">data</span><span class="p">);</span>  <span class="c1">// 2-3x faster!</span>
</code></pre></div></div>

<h3 id="real-world-analogy-7">Real-World Analogy</h3>

<p>Using a high-speed printer instead of an old dot-matrix printer to print the same document.</p>

<p><strong>Good for:</strong> High-traffic APIs with large response payloads</p>

<hr />

<h2 id="level-9-compression-shrink-the-data">Level 9: Compression (Shrink the Data)</h2>

<h3 id="what-is-it-8">What is it?</h3>

<p>Compress API responses before sending them over the network, reducing bandwidth and transfer time.</p>

<div class="mermaid">
sequenceDiagram
    participant C as ğŸ‘¤ Client
    participant S as ğŸ–¥ï¸ Server
    
    Note over C,S: âŒ Without Compression
    C-&gt;&gt;S: GET /api/data
    S--&gt;&gt;C: 1MB uncompressed (slow)
    Note over C: Download time: 8 seconds
    
    Note over C,S: âœ… With Compression (Gzip)
    C-&gt;&gt;S: GET /api/data<br />Accept-Encoding: gzip
    S--&gt;&gt;C: 100KB compressed (fast!)
    Note over C: Download time: 0.8 seconds ğŸš€
</div>

<h3 id="compression-algorithms">Compression Algorithms</h3>

<div class="mermaid">
flowchart TD
    subgraph comparison["Compression Comparison"]
        direction TB
        N["None: 1000KB"]
        G["Gzip: 150KB (85% smaller)"]
        B["Brotli: 120KB (88% smaller)"]
    end
    
    style N fill:#fecaca,stroke:#dc2626
    style G fill:#fef3c7,stroke:#d97706
    style B fill:#d1fae5,stroke:#059669
</div>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th>Compression</th>
      <th>Speed</th>
      <th>Browser Support</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Gzip</strong></td>
      <td>Good (70-80%)</td>
      <td>Fast</td>
      <td>âœ… Universal</td>
    </tr>
    <tr>
      <td><strong>Brotli</strong></td>
      <td>Better (75-85%)</td>
      <td>Medium</td>
      <td>âœ… Modern browsers</td>
    </tr>
    <tr>
      <td><strong>Deflate</strong></td>
      <td>Good (70-80%)</td>
      <td>Fast</td>
      <td>âœ… Universal</td>
    </tr>
  </tbody>
</table>

<h3 id="when-to-use-compression">When to Use Compression</h3>

<ul>
  <li>âœ… Text responses (JSON, HTML, CSS, JS)</li>
  <li>âœ… Responses larger than 1KB</li>
  <li>âŒ Already compressed data (images, videos)</li>
  <li>âŒ Very small responses (&lt; 1KB)</li>
</ul>

<h3 id="implementation-1">Implementation</h3>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Express.js (Node.js)</span>
<span class="kd">const</span> <span class="nx">compression</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">compression</span><span class="dl">'</span><span class="p">);</span>
<span class="nx">app</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="nf">compression</span><span class="p">());</span>  <span class="c1">// Automatically compress all responses</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Flask (Python)
</span><span class="kn">from</span> <span class="n">flask_compress</span> <span class="kn">import</span> <span class="n">Compress</span>
<span class="nc">Compress</span><span class="p">(</span><span class="n">app</span><span class="p">)</span>  <span class="c1"># Enable compression
</span></code></pre></div></div>

<div class="language-nginx highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Nginx configuration</span>
<span class="k">gzip</span> <span class="no">on</span><span class="p">;</span>
<span class="k">gzip_types</span> <span class="nc">application/json</span> <span class="nc">text/css</span> <span class="nc">application/javascript</span><span class="p">;</span>
<span class="k">gzip_min_length</span> <span class="mi">1000</span><span class="p">;</span>
</code></pre></div></div>

<h3 id="real-world-analogy-8">Real-World Analogy</h3>

<p>Vacuum-sealing clothes before packing them in a suitcase â€” same clothes, much less space.</p>

<p><strong>Good for:</strong> All text-based API responses</p>

<hr />

<h2 id="level-10-content-delivery-network-cdn">Level 10: Content Delivery Network (CDN)</h2>

<h3 id="what-is-it-9">What is it?</h3>

<p>A network of servers spread around the world that cache your content closer to users.</p>

<div class="mermaid">
flowchart TD
    subgraph origin["ğŸ  Your Origin Server<br />(New York)"]
        O["ğŸ–¥ï¸ Main Server"]
    end
    
    subgraph cdn["ğŸŒ CDN Edge Servers"]
        E1["ğŸ“¡ London"]
        E2["ğŸ“¡ Tokyo"]
        E3["ğŸ“¡ Sydney"]
        E4["ğŸ“¡ SÃ£o Paulo"]
    end
    
    O --&gt; E1
    O --&gt; E2
    O --&gt; E3
    O --&gt; E4
    
    U1["ğŸ‘¤ UK User"] --&gt; E1
    U2["ğŸ‘¤ Japan User"] --&gt; E2
    U3["ğŸ‘¤ Australia User"] --&gt; E3
    U4["ğŸ‘¤ Brazil User"] --&gt; E4
    
    style O fill:#dbeafe,stroke:#2563eb
    style E1 fill:#d1fae5,stroke:#059669
    style E2 fill:#d1fae5,stroke:#059669
    style E3 fill:#d1fae5,stroke:#059669
    style E4 fill:#d1fae5,stroke:#059669
</div>

<h3 id="without-cdn-vs-with-cdn">Without CDN vs With CDN</h3>

<table>
  <thead>
    <tr>
      <th>Â </th>
      <th>Without CDN</th>
      <th>With CDN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>User in Tokyo</strong></td>
      <td>Request travels to New York (200ms)</td>
      <td>Request goes to Tokyo edge (20ms)</td>
    </tr>
    <tr>
      <td><strong>Server Load</strong></td>
      <td>Every request hits your server</td>
      <td>Most requests served by CDN</td>
    </tr>
    <tr>
      <td><strong>Bandwidth Cost</strong></td>
      <td>You pay for all traffic</td>
      <td>CDN handles most traffic</td>
    </tr>
  </tbody>
</table>

<h3 id="real-world-analogy-9">Real-World Analogy</h3>

<p>Instead of one restaurant in New York, you open franchises worldwide. Customers get the same food from their local branch.</p>

<h3 id="best-for">Best For</h3>

<ul>
  <li>Static assets (images, CSS, JS)</li>
  <li>API responses that donâ€™t change per user</li>
  <li>Video streaming</li>
</ul>

<hr />

<h2 id="level-11-asynchronous-processing">Level 11: Asynchronous Processing</h2>

<h3 id="what-is-it-10">What is it?</h3>

<p>For slow operations, accept the request immediately and process it in the background.</p>

<div class="mermaid">
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant A as ğŸ–¥ï¸ API Server
    participant Q as ğŸ“¬ Message Queue
    participant W as âš™ï¸ Worker
    participant E as ğŸ“§ Email Service
    
    Note over U,E: âŒ Synchronous (Slow)
    U-&gt;&gt;A: POST /send-email
    A-&gt;&gt;E: Send email (3 seconds)
    E--&gt;&gt;A: Done
    A--&gt;&gt;U: 200 OK (waited 3 seconds ğŸ˜´)
    
    Note over U,E: âœ… Asynchronous (Fast)
    U-&gt;&gt;A: POST /send-email
    A-&gt;&gt;Q: Add to queue
    A--&gt;&gt;U: 202 Accepted (instant! ğŸš€)
    Q-&gt;&gt;W: Process job
    W-&gt;&gt;E: Send email
    Note over W: User already moved on!
</div>

<h3 id="common-use-cases">Common Use Cases</h3>

<table>
  <thead>
    <tr>
      <th>Operation</th>
      <th>Sync Time</th>
      <th>Async Benefit</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Send email</td>
      <td>2-5 seconds</td>
      <td>Instant response</td>
    </tr>
    <tr>
      <td>Generate PDF</td>
      <td>10+ seconds</td>
      <td>User doesnâ€™t wait</td>
    </tr>
    <tr>
      <td>Process payment</td>
      <td>3-5 seconds</td>
      <td>Faster checkout</td>
    </tr>
    <tr>
      <td>Resize image</td>
      <td>5-15 seconds</td>
      <td>Upload feels instant</td>
    </tr>
  </tbody>
</table>

<h3 id="tools">Tools</h3>

<ul>
  <li><strong>Message Queues:</strong> RabbitMQ, Amazon SQS, Redis</li>
  <li><strong>Task Processors:</strong> Celery (Python), Sidekiq (Ruby), Bull (Node.js)</li>
</ul>

<h3 id="real-world-analogy-10">Real-World Analogy</h3>

<p>At a busy restaurant, the waiter takes your order and immediately moves to the next table. The kitchen processes orders in the background.</p>

<hr />

<h2 id="level-12-asynchronous-logging">Level 12: Asynchronous Logging</h2>

<h3 id="what-is-it-11">What is it?</h3>

<p>Logging can slow down your API if it writes to disk synchronously. Async logging writes to a buffer first, then a background thread handles the disk writes.</p>

<div class="mermaid">
sequenceDiagram
    participant R as ğŸ“¨ Request
    participant A as ğŸ–¥ï¸ API Code
    participant B as ğŸ“ Buffer
    participant T as ğŸ§µ Background Thread
    participant D as ğŸ’¾ Disk
    
    Note over R,D: âŒ Synchronous Logging (Blocks request)
    R-&gt;&gt;A: Process request
    A-&gt;&gt;D: Write log (10ms) â³
    D--&gt;&gt;A: Done
    A--&gt;&gt;R: Response (slow)
    
    Note over R,D: âœ… Asynchronous Logging (Non-blocking)
    R-&gt;&gt;A: Process request
    A-&gt;&gt;B: Write to buffer (&lt; 1ms) âš¡
    A--&gt;&gt;R: Response (fast!)
    Note over B,T: Background thread
    T-&gt;&gt;B: Read from buffer
    T-&gt;&gt;D: Write log
</div>

<h3 id="performance-impact-1">Performance Impact</h3>

<div class="mermaid">
flowchart LR
    subgraph sync["âŒ Sync Logging"]
        direction TB
        S1["1000 requests"]
        S2["10ms per log write"]
        S3["10 seconds wasted"]
    end
    
    subgraph async["âœ… Async Logging"]
        direction TB
        A1["1000 requests"]
        A2["&lt; 1ms per log write"]
        A3["&lt; 1 second"]
    end
    
    sync --&gt;|10x faster| async
    
    style sync fill:#fecaca,stroke:#dc2626
    style async fill:#d1fae5,stroke:#059669
</div>

<h3 id="implementation-2">Implementation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Python with async logging
</span><span class="kn">import</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="n">logging.handlers</span> <span class="kn">import</span> <span class="n">QueueHandler</span><span class="p">,</span> <span class="n">QueueListener</span>
<span class="kn">from</span> <span class="n">queue</span> <span class="kn">import</span> <span class="n">Queue</span>

<span class="c1"># Create a queue for async logging
</span><span class="n">log_queue</span> <span class="o">=</span> <span class="nc">Queue</span><span class="p">()</span>

<span class="c1"># Main thread uses QueueHandler (non-blocking)
</span><span class="n">handler</span> <span class="o">=</span> <span class="nc">QueueHandler</span><span class="p">(</span><span class="n">log_queue</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="p">.</span><span class="nf">getLogger</span><span class="p">()</span>
<span class="n">logger</span><span class="p">.</span><span class="nf">addHandler</span><span class="p">(</span><span class="n">handler</span><span class="p">)</span>

<span class="c1"># Background thread processes the queue
</span><span class="n">listener</span> <span class="o">=</span> <span class="nc">QueueListener</span><span class="p">(</span><span class="n">log_queue</span><span class="p">,</span> <span class="n">logging</span><span class="p">.</span><span class="nc">FileHandler</span><span class="p">(</span><span class="sh">'</span><span class="s">app.log</span><span class="sh">'</span><span class="p">))</span>
<span class="n">listener</span><span class="p">.</span><span class="nf">start</span><span class="p">()</span>

<span class="c1"># Now logging is async!
</span><span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sh">'</span><span class="s">This is non-blocking</span><span class="sh">'</span><span class="p">)</span>  <span class="c1"># &lt; 1ms
</span></code></pre></div></div>

<div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">// Node.js with async logging (pino)</span>
<span class="kd">const</span> <span class="nx">pino</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">pino</span><span class="dl">'</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">logger</span> <span class="o">=</span> <span class="nf">pino</span><span class="p">({</span>
  <span class="na">transport</span><span class="p">:</span> <span class="p">{</span>
    <span class="na">target</span><span class="p">:</span> <span class="dl">'</span><span class="s1">pino/file</span><span class="dl">'</span><span class="p">,</span>
    <span class="na">options</span><span class="p">:</span> <span class="p">{</span> <span class="na">destination</span><span class="p">:</span> <span class="dl">'</span><span class="s1">app.log</span><span class="dl">'</span> <span class="p">}</span>
  <span class="p">}</span>
<span class="p">});</span>

<span class="c1">// Logs are buffered and written asynchronously</span>
<span class="nx">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="dl">'</span><span class="s1">This is non-blocking</span><span class="dl">'</span><span class="p">);</span>
</code></pre></div></div>

<h3 id="real-world-analogy-11">Real-World Analogy</h3>

<p>Instead of stopping to write down every detail in a notebook, you jot quick notes on sticky notes and organize them into the notebook later.</p>

<p><strong>Good for:</strong> High-traffic APIs with extensive logging</p>

<hr />

<h2 id="level-13-database-sharding-split-your-data">Level 13: Database Sharding (Split Your Data)</h2>

<h3 id="what-is-it-12">What is it?</h3>

<p>Divide your database into smaller pieces (shards), each handling a portion of the data.</p>

<div class="mermaid">
flowchart TD
    subgraph before["âŒ Single Database (Bottleneck)"]
        DB1["ğŸ—„ï¸ One Database<br />100M users"]
    end
    
    subgraph after["âœ… Sharded Database"]
        R["ğŸ”€ Router"]
        R --&gt; S1["ğŸ—„ï¸ Shard 1<br />Users A-H"]
        R --&gt; S2["ğŸ—„ï¸ Shard 2<br />Users I-P"]
        R --&gt; S3["ğŸ—„ï¸ Shard 3<br />Users Q-Z"]
    end
    
    style DB1 fill:#fecaca,stroke:#dc2626
    style R fill:#fef3c7,stroke:#d97706
    style S1 fill:#d1fae5,stroke:#059669
    style S2 fill:#d1fae5,stroke:#059669
    style S3 fill:#d1fae5,stroke:#059669
</div>

<h3 id="sharding-strategies">Sharding Strategies</h3>

<div class="mermaid">
flowchart LR
    subgraph range["Range-Based"]
        direction TB
        R1["Users 1-1M â†’ Shard 1"]
        R2["Users 1M-2M â†’ Shard 2"]
    end
    
    subgraph hash["Hash-Based"]
        direction TB
        H1["user_id % 3 = 0 â†’ Shard 1"]
        H2["user_id % 3 = 1 â†’ Shard 2"]
        H3["user_id % 3 = 2 â†’ Shard 3"]
    end
    
    subgraph geo["Geographic"]
        direction TB
        G1["US users â†’ US Shard"]
        G2["EU users â†’ EU Shard"]
    end
</div>

<h3 id="trade-offs">Trade-offs</h3>

<table>
  <thead>
    <tr>
      <th>Benefit</th>
      <th>Challenge</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>âœ… Each shard handles less load</td>
      <td>âŒ Cross-shard queries are complex</td>
    </tr>
    <tr>
      <td>âœ… Can scale horizontally</td>
      <td>âŒ Rebalancing shards is hard</td>
    </tr>
    <tr>
      <td>âœ… Failure affects only one shard</td>
      <td>âŒ Application logic becomes complex</td>
    </tr>
  </tbody>
</table>

<h3 id="real-world-analogy-12">Real-World Analogy</h3>

<p>Instead of one giant warehouse, you have regional warehouses. Each handles orders for their region.</p>

<p><strong>Good for:</strong> 100,000 â†’ 1,000,000+ RPS</p>

<hr />

<h2 id="level-14-rate-limiting-protect-your-system">Level 14: Rate Limiting (Protect Your System)</h2>

<h3 id="what-is-it-13">What is it?</h3>

<p>Limit how many requests a user or client can make in a given time period.</p>

<div class="mermaid">
sequenceDiagram
    participant U as ğŸ‘¤ User
    participant R as ğŸš¦ Rate Limiter
    participant A as ğŸ–¥ï¸ API
    
    U-&gt;&gt;R: Request 1
    R-&gt;&gt;A: âœ… Allow
    A--&gt;&gt;U: 200 OK
    
    U-&gt;&gt;R: Request 2
    R-&gt;&gt;A: âœ… Allow
    A--&gt;&gt;U: 200 OK
    
    U-&gt;&gt;R: Request 3
    R-&gt;&gt;A: âœ… Allow
    A--&gt;&gt;U: 200 OK
    
    Note over U,A: Limit reached (3 req/sec)
    
    U-&gt;&gt;R: Request 4
    R--&gt;&gt;U: âŒ 429 Too Many Requests
    
    U-&gt;&gt;R: Request 5
    R--&gt;&gt;U: âŒ 429 Too Many Requests
    
    Note over U,A: Wait 1 second...
    
    U-&gt;&gt;R: Request 6
    R-&gt;&gt;A: âœ… Allow
    A--&gt;&gt;U: 200 OK
</div>

<h3 id="common-algorithms-1">Common Algorithms</h3>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th>How it Works</th>
      <th>Visual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Token Bucket</strong></td>
      <td>Tokens added at fixed rate; request consumes a token</td>
      <td>ğŸª£ Bucket fills up over time</td>
    </tr>
    <tr>
      <td><strong>Sliding Window</strong></td>
      <td>Count requests in rolling time window</td>
      <td>ğŸ“Š Moving window of time</td>
    </tr>
    <tr>
      <td><strong>Fixed Window</strong></td>
      <td>Reset counter at fixed intervals</td>
      <td>â° Reset every minute</td>
    </tr>
  </tbody>
</table>

<h3 id="rate-limit-headers">Rate Limit Headers</h3>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HTTP/1.1 200 OK
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 67
X-RateLimit-Reset: 1640995200
</code></pre></div></div>

<h3 id="real-world-analogy-13">Real-World Analogy</h3>

<p>A bouncer at a club who only lets in 100 people per hour, no matter how long the line is.</p>

<hr />

<h2 id="the-complete-picture">The Complete Picture</h2>

<p>Hereâ€™s how all these techniques work together at scale:</p>

<div class="mermaid">
flowchart TB
    subgraph users["ğŸŒ Users Worldwide"]
        U1["ğŸ‘¤"]
        U2["ğŸ‘¤"]
        U3["ğŸ‘¤"]
    end
    
    subgraph edge["Edge Layer"]
        CDN["ğŸ“¡ CDN + Compression"]
        RL["ğŸš¦ Rate Limiter"]
    end
    
    subgraph app["Application Layer"]
        LB["âš–ï¸ Load Balancer"]
        S1["ğŸ–¥ï¸ Server<br />Fast JSON"]
        S2["ğŸ–¥ï¸ Server<br />Async Logging"]
        S3["ğŸ–¥ï¸ Server<br />Connection Pool"]
    end
    
    subgraph cache["Cache Layer"]
        RC["âš¡ Redis Cache"]
    end
    
    subgraph async["Async Layer"]
        Q["ğŸ“¬ Queue"]
        W["âš™ï¸ Workers"]
    end
    
    subgraph data["Data Layer<br />(Optimized Queries)"]
        SH1["ğŸ—„ï¸ Shard 1"]
        SH2["ğŸ—„ï¸ Shard 2"]
        SH3["ğŸ—„ï¸ Shard 3"]
    end
    
    U1 --&gt; CDN
    U2 --&gt; CDN
    U3 --&gt; CDN
    CDN --&gt; RL
    RL --&gt; LB
    LB --&gt; S1
    LB --&gt; S2
    LB --&gt; S3
    S1 --&gt; RC
    S2 --&gt; RC
    S3 --&gt; RC
    S1 --&gt; Q
    RC --&gt; SH1
    RC --&gt; SH2
    RC --&gt; SH3
    Q --&gt; W
    W --&gt; SH1
    
    style CDN fill:#d1fae5,stroke:#059669
    style RL fill:#fef3c7,stroke:#d97706
    style LB fill:#dbeafe,stroke:#2563eb
    style RC fill:#fce7f3,stroke:#db2777
    style Q fill:#e0e7ff,stroke:#6366f1
</div>

<hr />

<h2 id="scaling-roadmap">Scaling Roadmap</h2>

<table>
  <thead>
    <tr>
      <th>RPS Target</th>
      <th>Techniques to Add</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>1 â†’ 100</strong></td>
      <td>Vertical scaling, connection pooling, avoid N+1 queries</td>
    </tr>
    <tr>
      <td><strong>100 â†’ 1K</strong></td>
      <td>Caching (Redis), pagination, compression</td>
    </tr>
    <tr>
      <td><strong>1K â†’ 10K</strong></td>
      <td>Horizontal scaling, load balancer, fast JSON serializers</td>
    </tr>
    <tr>
      <td><strong>10K â†’ 100K</strong></td>
      <td>CDN, async processing, async logging</td>
    </tr>
    <tr>
      <td><strong>100K â†’ 1M</strong></td>
      <td>Database sharding, rate limiting, microservices</td>
    </tr>
    <tr>
      <td><strong>1M+</strong></td>
      <td>Multi-region deployment, edge computing</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="quick-reference-what-to-use-when">Quick Reference: What to Use When</h2>

<div class="mermaid">
flowchart TD
    Q["ğŸ¤” What's your bottleneck?"]
    
    Q --&gt; CPU["CPU maxed out?"]
    Q --&gt; MEM["Memory full?"]
    Q --&gt; DB["Database slow?"]
    Q --&gt; NET["Network saturated?"]
    Q --&gt; LOG["Logging slow?"]
    
    CPU --&gt; CPU_S["Add more servers<br />(horizontal scaling)"]
    MEM --&gt; MEM_S["Add caching<br />(Redis/Memcached)"]
    DB --&gt; DB_S["Connection pooling,<br />avoid N+1, sharding"]
    NET --&gt; NET_S["CDN, compression,<br />pagination"]
    LOG --&gt; LOG_S["Async logging"]
    
    style Q fill:#f1f5f9,stroke:#64748b
    style CPU_S fill:#d1fae5,stroke:#059669
    style MEM_S fill:#d1fae5,stroke:#059669
    style DB_S fill:#d1fae5,stroke:#059669
    style NET_S fill:#d1fae5,stroke:#059669
    style LOG_S fill:#d1fae5,stroke:#059669
</div>

<hr />

<h2 id="complete-summary">Complete Summary</h2>

<table>
  <thead>
    <tr>
      <th>Technique</th>
      <th>What It Does</th>
      <th>Impact</th>
      <th>When to Use</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Vertical Scaling</strong></td>
      <td>Bigger server</td>
      <td>Quick wins</td>
      <td>Start here</td>
    </tr>
    <tr>
      <td><strong>Horizontal Scaling</strong></td>
      <td>More servers</td>
      <td>High</td>
      <td>Growing traffic</td>
    </tr>
    <tr>
      <td><strong>Load Balancing</strong></td>
      <td>Distribute traffic</td>
      <td>High</td>
      <td>Multiple servers</td>
    </tr>
    <tr>
      <td><strong>Connection Pooling</strong></td>
      <td>Reuse DB connections</td>
      <td>Very High</td>
      <td>Always!</td>
    </tr>
    <tr>
      <td><strong>Avoid N+1 Queries</strong></td>
      <td>Optimize DB queries</td>
      <td>Very High</td>
      <td>Always!</td>
    </tr>
    <tr>
      <td><strong>Caching</strong></td>
      <td>Remember results</td>
      <td>Very High</td>
      <td>Repeated queries</td>
    </tr>
    <tr>
      <td><strong>Pagination</strong></td>
      <td>Send data in chunks</td>
      <td>High</td>
      <td>Large datasets</td>
    </tr>
    <tr>
      <td><strong>Fast JSON Serializers</strong></td>
      <td>Faster responses</td>
      <td>Medium</td>
      <td>High traffic</td>
    </tr>
    <tr>
      <td><strong>Compression</strong></td>
      <td>Smaller payloads</td>
      <td>High</td>
      <td>Text responses</td>
    </tr>
    <tr>
      <td><strong>CDN</strong></td>
      <td>Serve from edge</td>
      <td>High</td>
      <td>Global users</td>
    </tr>
    <tr>
      <td><strong>Async Processing</strong></td>
      <td>Background jobs</td>
      <td>High</td>
      <td>Slow operations</td>
    </tr>
    <tr>
      <td><strong>Async Logging</strong></td>
      <td>Non-blocking logs</td>
      <td>Medium</td>
      <td>Heavy logging</td>
    </tr>
    <tr>
      <td><strong>Database Sharding</strong></td>
      <td>Split data</td>
      <td>Very High</td>
      <td>Massive datasets</td>
    </tr>
    <tr>
      <td><strong>Rate Limiting</strong></td>
      <td>Protect system</td>
      <td>Medium</td>
      <td>Always!</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="bringing-it-all-together-your-scaling-journey">Bringing It All Together: Your Scaling Journey</h2>

<p>Scaling from 1 to 1 million RPS is not a single leapâ€”itâ€™s a series of strategic steps. Hereâ€™s how to think about your progression:</p>

<h3 id="phase-1-foundation-1-1k-rps">Phase 1: Foundation (1-1K RPS)</h3>
<p><strong>Focus:</strong> Get the basics right</p>
<ul>
  <li>âœ… Start with vertical scaling (bigger server)</li>
  <li>âœ… Implement connection pooling immediately</li>
  <li>âœ… Fix N+1 query problems</li>
  <li>âœ… Add basic caching for read-heavy operations</li>
  <li>âœ… Enable compression</li>
</ul>

<p><strong>Mindset:</strong> At this stage, a single well-configured server is sufficient. Donâ€™t over-engineer.</p>

<h3 id="phase-2-growth-1k-10k-rps">Phase 2: Growth (1K-10K RPS)</h3>
<p><strong>Focus:</strong> Distribute and optimize</p>
<ul>
  <li>âœ… Add horizontal scaling (multiple servers)</li>
  <li>âœ… Set up a load balancer</li>
  <li>âœ… Implement pagination for all list endpoints</li>
  <li>âœ… Use fast JSON serializers</li>
  <li>âœ… Expand caching strategy</li>
</ul>

<p><strong>Mindset:</strong> Your single server is maxed out. Time to distribute the load.</p>

<h3 id="phase-3-scale-10k-100k-rps">Phase 3: Scale (10K-100K RPS)</h3>
<p><strong>Focus:</strong> Edge optimization and async patterns</p>
<ul>
  <li>âœ… Deploy a CDN for static content and cacheable responses</li>
  <li>âœ… Move slow operations to async workers</li>
  <li>âœ… Implement async logging</li>
  <li>âœ… Optimize database with better indexing and query patterns</li>
</ul>

<p><strong>Mindset:</strong> Every millisecond counts. Optimize the request path and offload work.</p>

<h3 id="phase-4-massive-scale-100k-1m-rps">Phase 4: Massive Scale (100K-1M+ RPS)</h3>
<p><strong>Focus:</strong> Database distribution and protection</p>
<ul>
  <li>âœ… Implement database sharding</li>
  <li>âœ… Add rate limiting to protect against abuse</li>
  <li>âœ… Consider multi-region deployment</li>
  <li>âœ… Implement circuit breakers and failover mechanisms</li>
</ul>

<p><strong>Mindset:</strong> Youâ€™re operating at web scale. Focus on reliability, distribution, and resilience.</p>

<hr />

<h2 id="critical-success-factors">Critical Success Factors</h2>

<h3 id="1-measure-before-you-optimize">1. Measure Before You Optimize</h3>
<p>The bottleneck you imagine is rarely the real one. Use monitoring and profiling tools:</p>
<ul>
  <li><strong>Application Performance Monitoring (APM):</strong> New Relic, Datadog, or Grafana</li>
  <li><strong>Database Profiling:</strong> Identify slow queries with EXPLAIN plans</li>
  <li><strong>Load Testing:</strong> Use tools like k6, Gatling, or Apache JMeter</li>
</ul>

<p>Donâ€™t guessâ€”measure, identify the bottleneck, then fix it.</p>

<h3 id="2-implement-quick-wins-first">2. Implement Quick Wins First</h3>
<p>Some techniques have massive impact with minimal complexity:</p>
<ul>
  <li><strong>Connection pooling:</strong> 5-10x faster database operations</li>
  <li><strong>Avoid N+1 queries:</strong> 40x faster response times</li>
  <li><strong>Compression:</strong> 70-85% smaller payloads</li>
  <li><strong>Basic caching:</strong> 100x faster for repeated queries</li>
</ul>

<p>Start here before jumping to complex solutions.</p>

<h3 id="3-progressive-enhancement-over-big-rewrites">3. Progressive Enhancement Over Big Rewrites</h3>
<p>Add capabilities incrementally rather than rewriting everything:</p>
<ul>
  <li>Add caching without changing your API</li>
  <li>Add horizontal scaling without modifying application code</li>
  <li>Add async processing for new features first</li>
</ul>

<p>This reduces risk and delivers value continuously.</p>

<h3 id="4-know-when-not-to-scale">4. Know When NOT to Scale</h3>
<ul>
  <li><strong>Traffic patterns:</strong> Donâ€™t optimize for traffic spikes that happen once a year</li>
  <li><strong>Cost vs. benefit:</strong> Sometimes accepting slower responses is cheaper than scaling</li>
  <li><strong>Product stage:</strong> Pre-product-market fit? Focus on features, not scale</li>
</ul>

<p>Premature optimization wastes time and money.</p>

<hr />

<h2 id="common-scaling-mistakes-to-avoid">Common Scaling Mistakes to Avoid</h2>

<p>âŒ <strong>Mistake 1: Jumping to Microservices Too Early</strong>
A well-optimized monolith can handle 10,000+ RPS. Microservices add complexityâ€”only adopt them when you have clear organizational or technical reasons.</p>

<p>âŒ <strong>Mistake 2: Ignoring Database Optimization</strong>
Adding more application servers wonâ€™t help if your database is the bottleneck. Fix queries first.</p>

<p>âŒ <strong>Mistake 3: Not Testing Under Load</strong>
Load test before you have a problem, not during an outage. Know your limits.</p>

<p>âŒ <strong>Mistake 4: Caching Everything</strong>
Cache only whatâ€™s expensive to compute and read frequently. Over-caching adds complexity.</p>

<p>âŒ <strong>Mistake 5: Forgetting About Cache Invalidation</strong>
As Phil Karlton said: â€œThere are only two hard things in Computer Science: cache invalidation and naming things.â€ Plan your cache invalidation strategy from day one.</p>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li>
    <p><strong>Start Simple</strong>: A single optimized server with connection pooling, query optimization, and basic caching can handle 10,000+ RPS. Donâ€™t over-engineer early.</p>
  </li>
  <li>
    <p><strong>Measure First, Optimize Second</strong>: Use APM tools and profiling to find your actual bottlenecks. The problem is rarely where you think it is.</p>
  </li>
  <li><strong>Low-Hanging Fruit Matters Most</strong>:
    <ul>
      <li>Connection pooling (implement immediately)</li>
      <li>Avoid N+1 queries (implement immediately)</li>
      <li>Basic caching (implement early)</li>
      <li>Pagination (implement for all list endpoints)</li>
      <li>Compression (enable by default)</li>
    </ul>
  </li>
  <li><strong>Progressive Enhancement</strong>: Your architecture should evolve with your traffic:
    <ul>
      <li>1-1K RPS: Single server + optimizations</li>
      <li>1K-10K RPS: Horizontal scaling + load balancing</li>
      <li>10K-100K RPS: CDN + async patterns</li>
      <li>100K-1M+ RPS: Sharding + multi-region</li>
    </ul>
  </li>
  <li><strong>Always Profile</strong>: The bottleneck you imagine is rarely the real one. Measure, donâ€™t guess!</li>
</ol>

<hr />

<h2 id="final-thoughts">Final Thoughts</h2>

<p>Scaling is a journey, not a destination. The techniques in this guide will take you from handling your first user to serving millions. The key is to:</p>

<ul>
  <li><strong>Start with fundamentals</strong> (connection pooling, query optimization)</li>
  <li><strong>Add capabilities progressively</strong> (donâ€™t jump to advanced techniques)</li>
  <li><strong>Measure constantly</strong> (know your bottlenecks)</li>
  <li><strong>Optimize deliberately</strong> (focus on impact, not complexity)</li>
</ul>

<p>Remember: Twitter started as a Ruby on Rails monolith. Facebook started on a single server. Instagram scaled to 30+ million users with just 3 engineers. <strong>Good architecture and simple optimizations can take you incredibly far.</strong></p>

<p>Build for todayâ€™s needs with an eye toward tomorrowâ€™s scale. When you need the next level, youâ€™ll knowâ€”your monitoring will tell you. Until then, keep it simple and keep shipping. ğŸš€</p>

<hr />

<h2 id="continue-your-journey">Continue Your Journey</h2>

<p>This guide covered the <strong>technical and infrastructure</strong> aspects of scaling APIs. But as your organization grows, youâ€™ll face a different kind of scaling challenge: <strong>organizational and design complexity</strong>.</p>

<p><strong><a href="/handbook/handbook/_topics/scaling-api-design-architecture-part-2/">â†’ Continue to Part 2: Design &amp; Architecture Strategies</a></strong> to learn about:</p>
<ul>
  <li>API portfolio management</li>
  <li>Design-first methodologies</li>
  <li>Organizational patterns for large-scale API development</li>
  <li>Versioning strategies</li>
  <li>Governance and evangelism at scale</li>
</ul>

  </section>

  
  <footer class="topic-footer">
    <p>Tags: <span class="tag">scaling</span>, <span class="tag">performance</span>, <span class="tag">api</span>, <span class="tag">infrastructure</span></p>
  </footer>
  
</article>
    </main>

    <footer class="site-footer">
      <div class="container">
        <div class="footer-content">
          <p class="footer-author">Created by <strong>Rilov Paloly Kulankara</strong></p>
          <div class="footer-links">
            <a href="https://www.linkedin.com/in/rilov/" target="_blank" rel="noopener">LinkedIn</a>
            <span class="footer-divider">Â·</span>
            <a href="https://github.com/rilov" target="_blank" rel="noopener">GitHub</a>
            <span class="footer-divider">Â·</span>
            <a href="/handbook/about">About</a>
          </div>
          <p class="footer-copyright">&copy; 2025 Handbook</p>
        </div>
      </div>
    </footer>
    <script src="/handbook/assets/js/filter.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({ 
        startOnLoad: true,
        theme: 'base',
        themeVariables: {
          primaryColor: '#e0e7ff',
          primaryTextColor: '#1e293b',
          primaryBorderColor: '#2563eb',
          lineColor: '#64748b',
          secondaryColor: '#f1f5f9',
          tertiaryColor: '#fff'
        }
      });
    </script>
  </body>
</html>
