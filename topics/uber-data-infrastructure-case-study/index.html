<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Case Study: How Uber Built & Modernized Their Data Infrastructure</title>
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="icon" href="/handbook/assets/img/logo.svg" type="image/svg+xml">
    <link rel="stylesheet" href="/handbook/assets/css/style.css">
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <div class="site-brand">
          <a href="/handbook/" class="brand-link">
            <img src="/handbook/assets/img/logo.svg" alt="Handbook logo" width="36" height="36" />
          </a>
          <div>
            <h1><a href="/handbook/">Handbook</a></h1>
            <p class="site-desc">Quick tech ticks and comparisons</p>
          </div>
        </div>
        <nav class="site-nav" aria-label="Main">
          <a href="/handbook/">Home</a>
          <a href="/handbook/#categories">Categories</a>
          <a href="/handbook/about">About</a>
          <a href="https://github.com/rilov" target="_blank" rel="noopener">GitHub</a>
        </nav>
      </div>
    </header>

    <main class="container">
      <article class="topic">
  <header>
    <nav class="breadcrumb small">
      <a href="/handbook/">Home</a> &mdash;
      <a href="/handbook/categories/case-studies">Case Studies</a> &mdash;
    </nav>
    <h2>Case Study: How Uber Built & Modernized Their Data Infrastructure</h2>
    
      
      <p class="meta">Category: <a href="/handbook/categories/case-studies">Case Studies</a></p>
    
  </header>

  <section class="topic-body">
    <blockquote>
  <p><strong>What you‚Äôll learn:</strong> How one of the world‚Äôs largest tech companies built and then completely modernized their data infrastructure to handle billions of events per day. No technical background needed!</p>
</blockquote>

<h2 id="introduction-ubers-data-challenge">Introduction: Uber‚Äôs Data Challenge</h2>

<p>Imagine processing data for:</p>
<ul>
  <li><strong>137 million monthly active users</strong></li>
  <li><strong>7 billion trips per year</strong></li>
  <li><strong>Billions of events every single day</strong> (GPS locations, ride requests, payments, etc.)</li>
</ul>

<p>That‚Äôs Uber‚Äôs challenge. Every second, millions of data points are generated:</p>
<ul>
  <li>Riders requesting rides</li>
  <li>Drivers accepting requests</li>
  <li>GPS tracking every movement</li>
  <li>Payments being processed</li>
  <li>Maps being updated</li>
</ul>

<p><strong>The question:</strong> How do you store, process, and analyze all this data in real-time?</p>

<p>This case study shows how Uber solved this problem ‚Äî twice!</p>

<hr />

<h2 id="part-1-the-original-infrastructure-2015-2020">Part 1: The Original Infrastructure (2015-2020)</h2>

<h3 id="the-challenge-uber-faced">The Challenge Uber Faced</h3>

<p>Think of Uber like a massive restaurant chain that needs to know:</p>
<ul>
  <li>What every customer is ordering (ride requests)</li>
  <li>Where every delivery driver is (driver locations)</li>
  <li>How much everything costs (pricing, payments)</li>
  <li>What‚Äôs working and what‚Äôs not (analytics)</li>
  <li>All happening <strong>right now, in real-time</strong></li>
</ul>

<p>Traditional databases couldn‚Äôt handle this. Here‚Äôs why:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traditional Database (like PostgreSQL):
- Handles: 10,000 requests/second
- Uber's need: 1,000,000+ events/second
- Result: Database would crash! üî•
</code></pre></div></div>

<h3 id="ubers-original-solution-the-data-pipeline">Uber‚Äôs Original Solution: The Data Pipeline</h3>

<p>Uber built a complex but powerful system using multiple specialized tools:</p>

<div class="mermaid">
flowchart LR
    APPS["Uber Apps<br />(Riders &amp; Drivers)"] --&gt; KAFKA["Kafka<br />(Event Streaming)"]
    
    KAFKA --&gt; FLINK["Flink<br />(Real-time Processing)"]
    KAFKA --&gt; SPARK["Spark<br />(Batch Processing)"]
    
    FLINK --&gt; HDFS["HDFS<br />(Storage)"]
    SPARK --&gt; HDFS
    
    HDFS --&gt; HUDI["Hudi<br />(Data Lake)"]
    HUDI --&gt; PINOT["Pinot<br />(Analytics)"]
    HUDI --&gt; PRESTO["Presto<br />(Queries)"]
    
    PINOT --&gt; DASHBOARDS["Dashboards<br />(Insights)"]
    PRESTO --&gt; DASHBOARDS
    
    style APPS fill:#dbeafe,stroke:#2563eb
    style KAFKA fill:#fef3c7,stroke:#d97706
    style HDFS fill:#d1fae5,stroke:#059669
    style DASHBOARDS fill:#fce7f3,stroke:#db2777
</div>

<h3 id="breaking-down-the-components-simplified">Breaking Down the Components (Simplified)</h3>

<p>Let me explain each piece in simple terms:</p>

<h4 id="1-apache-kafka--the-event-highway">1. Apache Kafka ‚Äî The Event Highway</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A super-fast conveyor belt that moves millions of packages (data events) per second.</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Captures every event (ride request, GPS update, payment)</li>
  <li>Moves data at incredible speed (millions per second)</li>
  <li>Never loses data (even if something crashes)</li>
</ul>

<p><strong>Real example:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Rider opens app ‚Üí Kafka captures event
Driver accepts ‚Üí Kafka captures event
GPS updates location ‚Üí Kafka captures event
Payment processed ‚Üí Kafka captures event

All happening simultaneously for 137 million users!
</code></pre></div></div>

<h4 id="2-hdfs-hadoop-distributed-file-system--the-warehouse">2. HDFS (Hadoop Distributed File System) ‚Äî The Warehouse</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A massive warehouse that can store unlimited boxes (data files) across thousands of rooms (servers).</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Stores petabytes of data (1 petabyte = 1 million gigabytes!)</li>
  <li>Splits data across thousands of servers</li>
  <li>Never loses data (keeps 3 copies of everything)</li>
</ul>

<p><strong>Uber‚Äôs scale:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Data stored: Multiple petabytes
Files: Billions of files
Servers: Thousands of machines
Daily growth: Terabytes of new data every day
</code></pre></div></div>

<h4 id="3-apache-hudi--the-smart-librarian">3. Apache Hudi ‚Äî The Smart Librarian</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A librarian who can instantly update any book in a library of billions of books.</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Lets Uber update old data (like fixing a completed trip‚Äôs details)</li>
  <li>Keeps track of all changes (time travel - see data from yesterday)</li>
  <li>Makes querying fast even with billions of records</li>
</ul>

<p><strong>Why Uber needed it:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Problem: Can't update data in traditional data lakes
Uber's need: Update trip status, fix pricing errors, correct GPS data
Hudi's solution: Updates data in seconds, not hours
</code></pre></div></div>

<h4 id="4-apache-spark--the-batch-processor">4. Apache Spark ‚Äî The Batch Processor</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A factory that processes millions of items at once, overnight.</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Processes huge amounts of data in batches</li>
  <li>Runs complex calculations (pricing algorithms, demand prediction)</li>
  <li>Generates reports and summaries</li>
</ul>

<p><strong>Uber‚Äôs use cases:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Every night:
- Calculate driver earnings
- Generate surge pricing maps
- Create demand forecasts
- Build ML models

Processing: Petabytes of data in hours
</code></pre></div></div>

<h4 id="5-apache-flink--the-real-time-brain">5. Apache Flink ‚Äî The Real-Time Brain</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A super-fast chef who cooks orders the instant they come in (no waiting).</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Processes data in real-time (milliseconds)</li>
  <li>Detects patterns instantly (fraud, surge pricing)</li>
  <li>Updates dashboards live</li>
</ul>

<p><strong>Uber‚Äôs use cases:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Real-time:
- Surge pricing (demand spikes)
- Fraud detection (suspicious rides)
- Driver matching (find nearest driver)
- ETA calculation (time to arrival)

Response time: Under 1 second!
</code></pre></div></div>

<h4 id="6-apache-pinot--the-analytics-speed-demon">6. Apache Pinot ‚Äî The Analytics Speed Demon</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A super-smart calculator that can answer complex questions about billions of numbers instantly.</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Answers analytical queries in milliseconds</li>
  <li>Powers dashboards and reports</li>
  <li>Handles thousands of users querying simultaneously</li>
</ul>

<p><strong>Uber‚Äôs use cases:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Questions answered instantly:
- "How many rides in NYC right now?"
- "Average trip duration by city?"
- "Peak demand times this week?"
- "Driver earnings trends?"

Query time: 100-500 milliseconds!
</code></pre></div></div>

<h4 id="7-presto--the-query-language-translator">7. Presto ‚Äî The Query Language Translator</h4>

<blockquote>
  <p><strong>Think of it like:</strong> A universal translator that lets you ask questions in simple language about data stored anywhere.</p>
</blockquote>

<p><strong>What it does:</strong></p>
<ul>
  <li>Queries data across different systems (HDFS, databases, cloud storage)</li>
  <li>Uses SQL (simple query language)</li>
  <li>Federates queries (combines data from multiple sources)</li>
</ul>

<p><strong>Uber‚Äôs use cases:</strong></p>
<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- Data engineers can write simple queries:</span>
<span class="k">SELECT</span> <span class="n">city</span><span class="p">,</span> <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">as</span> <span class="n">rides</span>
<span class="k">FROM</span> <span class="n">trips</span>
<span class="k">WHERE</span> <span class="nb">date</span> <span class="o">=</span> <span class="s1">'2024-01-01'</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="n">city</span>

<span class="c1">-- Works across petabytes of data!</span>
</code></pre></div></div>

<hr />

<h3 id="how-it-all-worked-together">How It All Worked Together</h3>

<p>Here‚Äôs the complete flow of a single ride at Uber:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. CAPTURE (Kafka)
   Rider opens app ‚Üí Event captured ‚Üí Sent to Kafka
   
2. PROCESS (Flink - Real-time)
   Kafka ‚Üí Flink ‚Üí Match with nearest driver (100ms)
   
3. STORE (HDFS + Hudi)
   Trip data ‚Üí Saved to HDFS ‚Üí Indexed by Hudi
   
4. ANALYZE (Spark - Batch)
   Every night ‚Üí Calculate pricing, earnings, forecasts
   
5. QUERY (Pinot + Presto)
   Dashboards ‚Üí Query data ‚Üí Show insights
   
6. INSIGHTS
   Business teams see: trends, patterns, anomalies
</code></pre></div></div>

<h3 id="the-numbers-at-scale">The Numbers (At Scale)</h3>

<table>
  <thead>
    <tr>
      <th>Metric</th>
      <th>Scale</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Events per second</strong></td>
      <td>1,000,000+</td>
    </tr>
    <tr>
      <td><strong>Data processed daily</strong></td>
      <td>Multiple petabytes</td>
    </tr>
    <tr>
      <td><strong>Storage</strong></td>
      <td>Petabytes of data</td>
    </tr>
    <tr>
      <td><strong>Query latency</strong></td>
      <td>&lt; 1 second</td>
    </tr>
    <tr>
      <td><strong>Data retention</strong></td>
      <td>Years of historical data</td>
    </tr>
    <tr>
      <td><strong>Servers</strong></td>
      <td>Thousands of machines</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="part-2-the-modernization-2020-2024">Part 2: The Modernization (2020-2024)</h2>

<h3 id="why-uber-needed-to-change">Why Uber Needed to Change</h3>

<p>Even with this powerful system, Uber faced challenges:</p>

<h4 id="problem-1-complexity">Problem 1: Complexity</h4>

<blockquote>
  <p><strong>The issue:</strong> Managing dozens of different systems is like managing a city with 50 different public transport systems!</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>What Uber managed:
- Kafka clusters (event streaming)
- HDFS clusters (storage)
- Spark clusters (processing)
- Flink clusters (real-time)
- Pinot clusters (analytics)
- Presto clusters (queries)

Each needed:
- Separate teams to manage
- Different expertise
- Individual updates/patches
- Security management
- Monitoring systems

Result: Hundreds of engineers just to keep systems running!
</code></pre></div></div>

<h4 id="problem-2-cost">Problem 2: Cost</h4>

<blockquote>
  <p><strong>The issue:</strong> Running your own data centers is like owning and maintaining thousands of buildings.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Uber's costs:
- Server hardware (thousands of machines)
- Data centers (buildings, power, cooling)
- Network infrastructure
- Maintenance staff
- Upgrades and replacements

Annual cost: $100+ million just for infrastructure!
</code></pre></div></div>

<h4 id="problem-3-scalability-bottlenecks">Problem 3: Scalability Bottlenecks</h4>

<blockquote>
  <p><strong>The issue:</strong> Adding capacity meant buying more servers and waiting months.</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Traditional scaling:
1. Predict demand (guess next year's growth)
2. Order servers (3-6 months lead time)
3. Install in data center (weeks)
4. Configure and test (weeks)
5. Finally ready! (but demand changed)

Problem: Can't scale quickly during unexpected growth
</code></pre></div></div>

<h4 id="problem-4-global-expansion">Problem 4: Global Expansion</h4>

<blockquote>
  <p><strong>The issue:</strong> Uber operates in 70+ countries. Data needs to stay in each country (regulations).</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Problem:
- EU data must stay in EU (GDPR)
- Asia data must stay in Asia
- Need to replicate entire infrastructure in each region
- Maintaining consistency across regions = nightmare

Cost: 3x-5x more expensive per region
</code></pre></div></div>

<hr />

<h3 id="the-solution-google-cloud-platform-gcp">The Solution: Google Cloud Platform (GCP)</h3>

<p>Uber decided to modernize by moving to GCP. Here‚Äôs what changed:</p>

<div class="mermaid">
flowchart LR
    APPS["Uber Apps"] --&gt; PUBSUB["Pub/Sub<br />(replaces Kafka)"]
    
    PUBSUB --&gt; DATAFLOW["Dataflow<br />(replaces Flink/Spark)"]
    
    DATAFLOW --&gt; GCS["Cloud Storage<br />(replaces HDFS)"]
    DATAFLOW --&gt; BIGQUERY["BigQuery<br />(replaces Pinot/Presto/Hudi)"]
    
    BIGQUERY --&gt; LOOKER["Looker<br />(Dashboards)"]
    
    style APPS fill:#dbeafe,stroke:#2563eb
    style PUBSUB fill:#fef3c7,stroke:#d97706
    style GCS fill:#d1fae5,stroke:#059669
    style BIGQUERY fill:#fce7f3,stroke:#db2777
    style LOOKER fill:#e0e7ff,stroke:#6366f1
</div>

<h3 id="the-new-architecture-simplified">The New Architecture (Simplified)</h3>

<h4 id="1-google-cloud-pubsub-replaces-kafka">1. Google Cloud Pub/Sub (Replaces Kafka)</h4>

<blockquote>
  <p><strong>What changed:</strong> Instead of managing Kafka clusters, Google manages it for you.</p>
</blockquote>

<p><strong>Benefits:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Before (Kafka):
- Uber manages 100+ servers
- 24/7 on-call engineers
- Manual scaling
- Upgrade headaches

After (Pub/Sub):
- Google manages everything
- Auto-scaling
- Always available
- Pay only for what you use

Result: 10x fewer engineers needed!
</code></pre></div></div>

<h4 id="2-google-cloud-storage-replaces-hdfs">2. Google Cloud Storage (Replaces HDFS)</h4>

<blockquote>
  <p><strong>What changed:</strong> Instead of thousands of servers in data centers, data lives in Google‚Äôs cloud.</p>
</blockquote>

<p><strong>Benefits:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Before (HDFS):
- Own and maintain servers
- Manage disk failures
- Plan capacity months ahead
- Limited to data center locations

After (Cloud Storage):
- Google manages hardware
- Infinite storage
- Pay per GB used
- Available worldwide

Cost savings: 40-60% cheaper!
</code></pre></div></div>

<h4 id="3-bigquery-replaces-hudi--pinot--presto">3. BigQuery (Replaces Hudi + Pinot + Presto)</h4>

<blockquote>
  <p><strong>What changed:</strong> One system instead of three! This is like replacing 3 specialized tools with 1 Swiss Army knife.</p>
</blockquote>

<p><strong>The magic of BigQuery:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>What it does (all in one):
‚úÖ Stores petabytes of data (like Hudi)
‚úÖ Queries in milliseconds (like Pinot)
‚úÖ Uses SQL (like Presto)
‚úÖ Scales automatically
‚úÖ No servers to manage
‚úÖ Updates data easily

Uber's experience:
- Query time: Same speed (100-500ms)
- Capacity: Unlimited (auto-scales)
- Management: Zero servers to manage
- Cost: Pay only for queries run

Example:
Query 10 TB of data ‚Üí Takes 5 seconds ‚Üí Costs $5
</code></pre></div></div>

<h4 id="4-dataflow-replaces-spark--flink">4. Dataflow (Replaces Spark + Flink)</h4>

<blockquote>
  <p><strong>What changed:</strong> One managed service for both real-time and batch processing.</p>
</blockquote>

<p><strong>Benefits:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Before:
- Manage Spark clusters (batch)
- Manage Flink clusters (real-time)
- Two different systems, two teams

After:
- One Dataflow service
- Handles both real-time and batch
- Google manages infrastructure
- Auto-scales based on load

Complexity: Reduced by 50%!
</code></pre></div></div>

<hr />

<h3 id="the-migration-journey">The Migration Journey</h3>

<p>Uber didn‚Äôt switch overnight. Here‚Äôs how they did it:</p>

<h4 id="phase-1-pilot-6-months">Phase 1: Pilot (6 months)</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 1: Choose one small use case
- Selected: Trip analytics (non-critical)
- Migrated 5% of data
- Tested thoroughly

Result: Success! 40% faster, 50% cheaper
</code></pre></div></div>

<h4 id="phase-2-gradual-migration-18-months">Phase 2: Gradual Migration (18 months)</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 2: Migrate by priority
- Month 1-6: Analytics and reporting
- Month 7-12: Real-time dashboards
- Month 13-18: Critical systems

Strategy: Run both systems in parallel
- Old system: Production
- New system: Shadow (testing)
- Validate: Compare results

Result: Zero downtime!
</code></pre></div></div>

<h4 id="phase-3-full-migration-12-months">Phase 3: Full Migration (12 months)</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Step 3: Move everything
- Migrate remaining systems
- Shut down old infrastructure
- Train teams on new tools

Final result: 100% on GCP
</code></pre></div></div>

<hr />

<h3 id="the-results-what-changed">The Results: What Changed?</h3>

<h4 id="1-cost-savings">1. Cost Savings</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Infrastructure costs:
Before: $100+ million/year
After:  $60 million/year
Savings: 40% reduction

Why?
- No server hardware to buy
- No data centers to maintain
- Pay only for what you use
- Auto-scaling prevents over-provisioning
</code></pre></div></div>

<h4 id="2-speed-improvements">2. Speed Improvements</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Development time:
Before: 3-6 months to launch new data product
After:  2-4 weeks

Why?
- No infrastructure setup needed
- Pre-built integrations
- Self-service for data teams
</code></pre></div></div>

<h4 id="3-reliability">3. Reliability</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>System uptime:
Before: 99.9% (9 hours downtime/year)
After:  99.99% (52 minutes downtime/year)

Why?
- Google's infrastructure is battle-tested
- Automatic failover
- Built-in redundancy
</code></pre></div></div>

<h4 id="4-scalability">4. Scalability</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scaling time:
Before: 3-6 months (buy servers, install, configure)
After:  Automatic (scales in minutes)

Example:
- Black Friday traffic spike (10x normal)
- Old system: Would crash or need months of prep
- New system: Auto-scales, handles spike perfectly
</code></pre></div></div>

<h4 id="5-global-expansion">5. Global Expansion</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>New region setup:
Before: 6-12 months, $10+ million
After:  1-2 weeks, $1 million

Why?
- No need to build data centers
- Just enable GCP regions
- Copy configurations
- Done!

Result: Uber expanded to 20 new countries in 2 years
</code></pre></div></div>

<hr />

<h2 id="key-lessons-for-your-business">Key Lessons for Your Business</h2>

<h3 id="lesson-1-start-simple-scale-later">Lesson 1: Start Simple, Scale Later</h3>

<blockquote>
  <p><strong>Uber‚Äôs mistake:</strong> Built complex system too early</p>

  <p><strong>Better approach:</strong> Start with simple cloud services, add complexity only when needed</p>
</blockquote>

<p><strong>For your startup:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Don't build like Uber (initially)!

Start with:
- Simple database (PostgreSQL)
- Managed services (AWS RDS, GCP BigQuery)
- Basic analytics tools

Add complexity only when:
- Handling 100K+ requests/second
- Processing petabytes of data
- Operating in 10+ countries
</code></pre></div></div>

<h3 id="lesson-2-managed-services-save-money">Lesson 2: Managed Services Save Money</h3>

<blockquote>
  <p><strong>Uber‚Äôs learning:</strong> Managing infrastructure is expensive</p>
</blockquote>

<p><strong>Cost breakdown:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Self-managed (like old Uber):
- Infrastructure: $100M
- Engineers: $50M (salaries)
- Total: $150M/year

Managed (like new Uber):
- Infrastructure: $60M (GCP)
- Engineers: $20M (fewer needed)
- Total: $80M/year

Savings: $70M/year (47% reduction)
</code></pre></div></div>

<h3 id="lesson-3-migration-takes-time">Lesson 3: Migration Takes Time</h3>

<blockquote>
  <p><strong>Uber‚Äôs approach:</strong> 3 years to fully migrate</p>
</blockquote>

<p><strong>Your migration timeline:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Small company (&lt; 10 engineers):
- Plan: 1 month
- Migrate: 3-6 months
- Optimize: 3 months
- Total: 6-12 months

Enterprise (100+ engineers):
- Plan: 6 months
- Migrate: 18-36 months
- Optimize: 12 months
- Total: 3-5 years

Key: Don't rush! Parallel run old and new systems
</code></pre></div></div>

<h3 id="lesson-4-cloud-isnt-always-cheaper-initially">Lesson 4: Cloud isn‚Äôt Always Cheaper (Initially)</h3>

<blockquote>
  <p><strong>Uber‚Äôs reality:</strong> First year cost MORE, long-term saved money</p>
</blockquote>

<p><strong>Cost curve:</strong></p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Year 1: $120M (running both systems)
Year 2: $80M (mostly migrated)
Year 3: $60M (fully migrated)
Year 4+: $60M (stable)

Total 4-year cost:
Old approach: $400M
New approach: $320M
Savings: $80M over 4 years

ROI: Positive after 2.5 years
</code></pre></div></div>

<hr />

<h2 id="the-technology-stack-comparison">The Technology Stack Comparison</h2>

<h3 id="old-stack-self-managed">Old Stack (Self-Managed)</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Purpose</th>
      <th>Complexity</th>
      <th>Cost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Kafka</td>
      <td>Event streaming</td>
      <td>High</td>
      <td>High</td>
    </tr>
    <tr>
      <td>HDFS</td>
      <td>Storage</td>
      <td>Very High</td>
      <td>Very High</td>
    </tr>
    <tr>
      <td>Hudi</td>
      <td>Data lake</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <td>Spark</td>
      <td>Batch processing</td>
      <td>High</td>
      <td>High</td>
    </tr>
    <tr>
      <td>Flink</td>
      <td>Real-time processing</td>
      <td>Very High</td>
      <td>High</td>
    </tr>
    <tr>
      <td>Pinot</td>
      <td>Analytics</td>
      <td>High</td>
      <td>Medium</td>
    </tr>
    <tr>
      <td>Presto</td>
      <td>Queries</td>
      <td>Medium</td>
      <td>Medium</td>
    </tr>
  </tbody>
</table>

<p><strong>Total complexity:</strong> ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Maximum)
<strong>Total cost:</strong> \(\)$ (Very expensive)
<strong>Management:</strong> 300+ engineers needed</p>

<h3 id="new-stack-gcp-managed">New Stack (GCP Managed)</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Purpose</th>
      <th>Complexity</th>
      <th>Cost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pub/Sub</td>
      <td>Event streaming</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <td>Cloud Storage</td>
      <td>Storage</td>
      <td>Very Low</td>
      <td>Low</td>
    </tr>
    <tr>
      <td>BigQuery</td>
      <td>Analytics + queries + data lake</td>
      <td>Low</td>
      <td>Medium</td>
    </tr>
    <tr>
      <td>Dataflow</td>
      <td>Batch + real-time processing</td>
      <td>Medium</td>
      <td>Medium</td>
    </tr>
    <tr>
      <td>Looker</td>
      <td>Dashboards</td>
      <td>Low</td>
      <td>Low</td>
    </tr>
  </tbody>
</table>

<p><strong>Total complexity:</strong> ‚≠ê‚≠ê (Much simpler)
<strong>Total cost:</strong> $$$ (Cheaper)
<strong>Management:</strong> 100 engineers needed</p>

<hr />

<h2 id="what-this-means-for-you">What This Means for You</h2>

<h3 id="if-youre-a-startup">If You‚Äôre a Startup</h3>

<p><strong>Don‚Äôt build like Uber!</strong> Start with:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Phase 1 (0-100K users):
- Database: PostgreSQL (managed)
- Analytics: Google Analytics / Mixpanel
- Cost: $100-500/month

Phase 2 (100K-1M users):
- Database: PostgreSQL + Redis cache
- Analytics: BigQuery
- Cost: $1K-5K/month

Phase 3 (1M-10M users):
- Database: PostgreSQL + MongoDB
- Analytics: BigQuery + Looker
- Streaming: Pub/Sub (if needed)
- Cost: $10K-50K/month

Only at 10M+ users:
Consider Uber-level infrastructure
</code></pre></div></div>

<h3 id="if-youre-mid-size-company">If You‚Äôre Mid-Size Company</h3>

<p><strong>Consider managed services:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Instead of building:
‚úÖ Use BigQuery (instead of building data warehouse)
‚úÖ Use Pub/Sub (instead of managing Kafka)
‚úÖ Use Cloud Storage (instead of HDFS)
‚úÖ Use Dataflow (instead of Spark/Flink)

Benefits:
- 50% cheaper long-term
- 80% less complexity
- 5x faster to market
- Focus engineers on product, not infrastructure
</code></pre></div></div>

<h3 id="if-youre-enterprise">If You‚Äôre Enterprise</h3>

<p><strong>Uber‚Äôs migration playbook:</strong></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Year 1: Assessment
- Audit current infrastructure
- Calculate costs (TCO)
- Identify pain points
- Build business case
- Get executive buy-in

Year 2-3: Migration
- Start with non-critical systems
- Run in parallel (old + new)
- Validate results
- Train teams
- Gradually migrate critical systems

Year 4: Optimization
- Shut down old infrastructure
- Optimize cloud costs
- Document learnings
- Celebrate wins!
</code></pre></div></div>

<hr />

<h2 id="summary-ubers-data-infrastructure-journey">Summary: Uber‚Äôs Data Infrastructure Journey</h2>

<blockquote>
  <p><strong>What we learned:</strong></p>
</blockquote>

<h3 id="the-old-system-2015-2020">The Old System (2015-2020)</h3>

<p><strong>Built to handle:</strong></p>
<ul>
  <li>137 million monthly users</li>
  <li>1 million+ events/second</li>
  <li>Petabytes of data</li>
</ul>

<p><strong>Components:</strong></p>
<ul>
  <li>Kafka ‚Üí Event streaming</li>
  <li>HDFS ‚Üí Storage</li>
  <li>Hudi ‚Üí Data lake</li>
  <li>Spark ‚Üí Batch processing</li>
  <li>Flink ‚Üí Real-time processing</li>
  <li>Pinot ‚Üí Analytics</li>
  <li>Presto ‚Üí Queries</li>
</ul>

<p><strong>Problems:</strong></p>
<ul>
  <li>Complex (300+ engineers to manage)</li>
  <li>Expensive ($150M/year)</li>
  <li>Slow to scale (months)</li>
  <li>Hard to expand globally</li>
</ul>

<h3 id="the-new-system-2020-2024">The New System (2020-2024)</h3>

<p><strong>Migrated to GCP:</strong></p>
<ul>
  <li>Pub/Sub ‚Üí Event streaming</li>
  <li>Cloud Storage ‚Üí Storage</li>
  <li>BigQuery ‚Üí Everything else!</li>
  <li>Dataflow ‚Üí Processing</li>
</ul>

<p><strong>Benefits:</strong></p>
<ul>
  <li>Simpler (100 engineers needed)</li>
  <li>Cheaper ($80M/year, 47% savings)</li>
  <li>Fast to scale (automatic)</li>
  <li>Easy global expansion</li>
</ul>

<p><strong>Migration:</strong></p>
<ul>
  <li>Took 3 years</li>
  <li>Zero downtime</li>
  <li>Massive success</li>
</ul>

<hr />

<h2 id="key-takeaways">Key Takeaways</h2>

<ol>
  <li><strong>Start Simple:</strong> Don‚Äôt build Uber-scale infrastructure for a small app</li>
  <li><strong>Managed Services Win:</strong> Let cloud providers handle infrastructure</li>
  <li><strong>Migration Takes Time:</strong> Plan for years, not months</li>
  <li><strong>It‚Äôs Worth It:</strong> Long-term savings are massive</li>
</ol>

<p><strong>The bottom line:</strong> Even the most complex tech companies are moving to managed cloud services. If Uber can simplify, you can too!</p>

<hr />

<h2 id="further-reading">Further Reading</h2>

<ul>
  <li><a href="https://www.uber.com/blog/engineering/">Uber‚Äôs Engineering Blog</a></li>
  <li><a href="https://cloud.google.com/customers/uber">Google Cloud Case Study: Uber</a></li>
  <li><a href="https://kafka.apache.org/documentation/">Apache Kafka Documentation</a></li>
  <li><a href="https://cloud.google.com/bigquery/docs">BigQuery Documentation</a></li>
  <li><a href="https://www.databricks.com/glossary/data-engineering">Data Engineering Best Practices</a></li>
</ul>

  </section>

  
  <footer class="topic-footer">
    <p>Tags: <span class="tag">case-study</span>, <span class="tag">uber</span>, <span class="tag">data-infrastructure</span>, <span class="tag">gcp</span>, <span class="tag">kafka</span>, <span class="tag">real-world</span></p>
  </footer>
  
</article>
    </main>

    <footer class="site-footer">
      <div class="container">
        <div class="footer-content">
          <p class="footer-author">Created by <strong>Rilov Paloly Kulankara</strong></p>
          <div class="footer-links">
            <a href="https://www.linkedin.com/in/rilov/" target="_blank" rel="noopener">LinkedIn</a>
            <span class="footer-divider">¬∑</span>
            <a href="https://github.com/rilov" target="_blank" rel="noopener">GitHub</a>
            <span class="footer-divider">¬∑</span>
            <a href="/handbook/about">About</a>
          </div>
          <p class="footer-copyright">&copy; 2025 Handbook</p>
        </div>
      </div>
    </footer>
    <script src="/handbook/assets/js/filter.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
    <script>
      mermaid.initialize({ 
        startOnLoad: true,
        theme: 'base',
        themeVariables: {
          primaryColor: '#e0e7ff',
          primaryTextColor: '#1e293b',
          primaryBorderColor: '#2563eb',
          lineColor: '#64748b',
          secondaryColor: '#f1f5f9',
          tertiaryColor: '#fff'
        }
      });
    </script>
  </body>
</html>
