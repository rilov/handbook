{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - LangChain Foundations: Understanding LLMs and Orchestration\n",
    "\n",
    "This notebook accompanies the LangChain Foundations tutorial. Work through this notebook to practice the concepts hands-on.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- What LLMs are and their limitations\n",
    "- Why we need LangChain and LangGraph\n",
    "- The concept of orchestration\n",
    "- When to use each tool\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup\n",
    "\n",
    "First, let's install the required packages and set up our API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîë Configure API Keys\n",
    "\n",
    "You'll need an OpenAI API key to run the examples. Get one at: https://platform.openai.com/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Enter your API key when prompted\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"‚úÖ API key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Understanding LLMs\n",
    "\n",
    "An **LLM (Large Language Model)** is like a super-smart autocomplete system trained on massive amounts of text.\n",
    "\n",
    "Let's test a basic LLM call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a basic LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "\n",
    "# Ask a simple question\n",
    "response = llm.invoke(\"Explain what an LLM is in one sentence.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üî¨ Experiment: LLM Limitations\n",
    "\n",
    "Let's see the limitations of a bare LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try asking for current information\n",
    "print(\"Question 1: What's the weather right now?\")\n",
    "response1 = llm.invoke(\"What's the weather in New York right now?\")\n",
    "print(f\"Answer: {response1.content}\")\n",
    "print(\"\\n‚ùå Notice: It can't check real weather!\\n\")\n",
    "\n",
    "# Try asking about personal data\n",
    "print(\"Question 2: Personal information\")\n",
    "response2 = llm.invoke(\"What files do I have on my computer?\")\n",
    "print(f\"Answer: {response2.content}\")\n",
    "print(\"\\n‚ùå Notice: It has no access to your files!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß What LangChain Solves\n",
    "\n",
    "**LangChain** provides:\n",
    "1. Connectors to databases, files, APIs\n",
    "2. Tools for the LLM to use\n",
    "3. Memory systems\n",
    "4. Pre-built patterns\n",
    "\n",
    "### Example: Simple Chain\n",
    "\n",
    "Let's create a simple chain that shows how LangChain structures workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create a prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful teacher explaining concepts simply.\"),\n",
    "    (\"user\", \"{topic}\")\n",
    "])\n",
    "\n",
    "# Create a chain: prompt ‚Üí llm ‚Üí parse output\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Use the chain\n",
    "result = chain.invoke({\"topic\": \"What is orchestration in AI systems?\"})print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üåä Understanding LangGraph\n",
    "\n",
    "**LangGraph** is for complex workflows with:\n",
    "- Loops and conditionals\n",
    "- Multiple decision points\n",
    "- State management\n",
    "\n",
    "### Simple Example: Conditional Flow\n",
    "\n",
    "Here's a basic example showing how LangGraph can make decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a conceptual example - we'll build real LangGraph apps in Part 5\n",
    "\n",
    "def simple_decision_flow(question: str):\n",
    "    \"\"\"Simulate a simple decision flow like LangGraph provides.\"\"\"\n",
    "    \n",
    "    print(f\"üì• Input: {question}\")\n",
    "    \n",
    "    # Step 1: Analyze the question\n",
    "    if \"?\" in question:\n",
    "        print(\"ü§î Decision: This is a question, needs research\")\n",
    "        action = \"search\"\n",
    "    else:\n",
    "        print(\"ü§î Decision: This is a statement, can answer directly\")\n",
    "        action = \"answer\"\n",
    "    \n",
    "    # Step 2: Take action\n",
    "    if action == \"search\":\n",
    "        print(\"üîç Action: Searching for information...\")\n",
    "        result = \"[Simulated search results]\"\n",
    "    else:\n",
    "        result = \"[Direct answer]\"\n",
    "    \n",
    "    print(f\"‚úÖ Output: {result}\")\n",
    "    return result\n",
    "\n",
    "# Test it\n",
    "simple_decision_flow(\"What is LangChain?\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "simple_decision_flow(\"LangChain is awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ When to Use What\n",
    "\n",
    "Let's practice identifying which tool to use for different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    {\n",
    "        \"task\": \"Generate a poem\",\n",
    "        \"answer\": \"Raw LLM API\",\n",
    "        \"reason\": \"Simple one-shot generation\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Answer questions from company PDFs\",\n",
    "        \"answer\": \"LangChain (RAG)\",\n",
    "        \"reason\": \"Need to connect to documents\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Research assistant that can search web and take notes\",\n",
    "        \"answer\": \"LangGraph (Agent)\",\n",
    "        \"reason\": \"Complex workflow with multiple tools and decisions\"\n",
    "    },\n",
    "    {\n",
    "        \"task\": \"Translate text to Spanish\",\n",
    "        \"answer\": \"Raw LLM API\",\n",
    "        \"reason\": \"Simple transformation task\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üìã Decision Guide Examples:\\n\")\n",
    "for i, scenario in enumerate(scenarios, 1):\n",
    "    print(f\"{i}. Task: {scenario['task']}\")\n",
    "    print(f\"   ‚úÖ Use: {scenario['answer']}\")\n",
    "    print(f\"   üí° Why: {scenario['reason']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Practice Exercises\n",
    "\n",
    "Try these exercises to reinforce your learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Test LLM Responses\n",
    "\n",
    "Ask the LLM different types of questions and observe the responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try asking your own questions\n",
    "your_question = \"YOUR_QUESTION_HERE\"  # Replace with your question\n",
    "\n",
    "response = llm.invoke(your_question)\n",
    "print(f\"Q: {your_question}\")\n",
    "print(f\"A: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Simple Chain\n",
    "\n",
    "Create your own chain with a custom system message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain that explains things like you're 5 years old\n",
    "eli5_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Explain concepts as if talking to a 5-year-old child. Use simple words and fun examples.\"),\n",
    "    (\"user\", \"{concept}\")\n",
    "])\n",
    "\n",
    "eli5_chain = eli5_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Test it\n",
    "result = eli5_chain.invoke({\"concept\": \"artificial intelligence\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Summary\n",
    "\n",
    "You've learned:\n",
    "\n",
    "‚úÖ **LLMs** are powerful but limited (no real-world access, no memory)\n",
    "‚úÖ **LangChain** connects LLMs to tools, data, and workflows\n",
    "‚úÖ **LangGraph** handles complex workflows with decisions and loops\n",
    "‚úÖ **Orchestration** means coordinating all these components\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Continue to **Part 2 - LangChain Essentials** to learn about:\n",
    "- Chat models and temperature\n",
    "- Prompting patterns\n",
    "- Structured outputs\n",
    "- Chaining with LCEL\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs/)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations on completing Part 1!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
