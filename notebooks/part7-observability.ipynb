{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Part 7 - Observability with LangSmith\n\nLearn to debug and monitor your AI applications."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["!pip install -q langchain langchain-openai langsmith"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Setup LangSmith Tracing"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import os\nimport getpass\n\nif not os.getenv('OPENAI_API_KEY'):\n    os.environ['OPENAI_API_KEY'] = getpass.getpass('Enter OpenAI API key: ')\n\nif not os.getenv('LANGCHAIN_API_KEY'):\n    os.environ['LANGCHAIN_API_KEY'] = getpass.getpass('Enter LangSmith API key: ')\n\nos.environ['LANGCHAIN_TRACING_V2'] = 'true'\nos.environ['LANGCHAIN_PROJECT'] = 'notebook-demo'\n\nprint('âœ… Tracing enabled! Check smith.langchain.com')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Run a Traced Chain"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["from langchain_openai import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nprompt = ChatPromptTemplate.from_template('Explain {topic} simply')\nmodel = ChatOpenAI()\nchain = prompt | model | StrOutputParser()\n\n# This will be traced in LangSmith\nresult = chain.invoke({'topic': 'quantum computing'})\nprint(result)\nprint('\\nðŸ” Check LangSmith dashboard for trace!')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Add Custom Metadata"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["from langsmith import traceable\n\n@traceable(name='custom_function', tags=['demo', 'v1'])\ndef process_query(query: str) -> str:\n    '''Custom function with tracing.'''\n    model = ChatOpenAI()\n    response = model.invoke(query)\n    return response.content\n\nresult = process_query('What is LangSmith?')\nprint(result)"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## View Traces\n\nGo to https://smith.langchain.com to see:\n- Input/output of each step\n- Token usage and costs\n- Timing information\n- Error details"]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
